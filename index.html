<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no">
<meta name="author" content="Fvelement">


    
    


<meta property="og:type" content="website">
<meta property="og:title" content="Fvelement">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Fvelement">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fvelement">

<link rel="apple-touch-icon" href="/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="Fvelement" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">


    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Fvelement</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head></html>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/Coding.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Fvelement</a></h1>
        </hgroup>

        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false">
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class="no-result">No results found <i class="fa fa-spinner fa-pulse"></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:262986832@qq.com" title="Email"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Filebeat/">Filebeat</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/elk/">elk</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pulsar/">pulsar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/消息中间件/">消息中间件</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">绝知此事要躬行</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Fvelement</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/Coding.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Fvelement</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:262986832@qq.com" title="Email"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我">
</nav>
      <div class="body-wrap">
  
    <article id="post-pulsar总结" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/04/17/pulsar总结/" class="article-date">
      <time datetime="2019-04-17T09:57:54.000Z" itemprop="datePublished">2019-04-17</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/17/pulsar总结/">pulsar消息中间件总结</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="Pulsar消息中间件选型"><a href="#Pulsar消息中间件选型" class="headerlink" title="Pulsar消息中间件选型"></a><a href="https://262986832.github.io/2019/03/29/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6pulsar%EF%BC%8C%E9%80%89%E5%9E%8B%E4%B8%8E%E8%AF%84%E6%B5%8B/" target="_blank" rel="noopener">Pulsar消息中间件选型</a></h3><h3 id="Pulsar系统架构和设计理念"><a href="#Pulsar系统架构和设计理念" class="headerlink" title="Pulsar系统架构和设计理念"></a><a href="https://262986832.github.io/2019/04/01/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%92%8C%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/" target="_blank" rel="noopener">Pulsar系统架构和设计理念</a></h3><h3 id="Pulsar生产系统规划建议"><a href="#Pulsar生产系统规划建议" class="headerlink" title="Pulsar生产系统规划建议"></a><a href>Pulsar生产系统规划建议</a></h3><h3 id="Pulsar安装"><a href="#Pulsar安装" class="headerlink" title="Pulsar安装"></a><a href>Pulsar安装</a></h3><h3 id="Pulsar测试脚本"><a href="#Pulsar测试脚本" class="headerlink" title="Pulsar测试脚本"></a><a href>Pulsar测试脚本</a></h3><h3 id="Pulsar安全认证"><a href="#Pulsar安全认证" class="headerlink" title="Pulsar安全认证"></a>Pulsar安全认证</h3><ul>
<li><a href>Pulsar对称算法生成token</a></li>
<li><a href>Pulsar非对称生成token</a></li>
</ul>
<h3 id="Pulsar的CDC数据源对接mysql"><a href="#Pulsar的CDC数据源对接mysql" class="headerlink" title="Pulsar的CDC数据源对接mysql"></a><a href>Pulsar的CDC数据源对接mysql</a></h3>
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pulsar/">pulsar</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/消息中间件/">消息中间件</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-mysql-常用命令及脑图" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/04/10/mysql-常用命令及脑图/" class="article-date">
      <time datetime="2019-04-10T03:08:47.000Z" itemprop="datePublished">2019-04-10</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/10/mysql-常用命令及脑图/">mysql 常用命令及脑图</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="UPDATE-command-denied-to-user-‘debezium‘-’localhost’-for-table-‘products’"><a href="#UPDATE-command-denied-to-user-‘debezium‘-’localhost’-for-table-‘products’" class="headerlink" title="UPDATE command denied to user ‘debezium‘@’localhost’ for table ‘products’"></a>UPDATE command denied to user ‘debezium‘@’localhost’ for table ‘products’</h3><p>‘’’<br>SELECT USER();<br>SHOW GRANTS FOR  ‘debezium@localhost’<br>GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, INDEX, ALTER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE ON <code>inventory</code>.* TO ‘debezium@localhost’<br>‘’’</p>
<h3 id="ERROR-1044-42000-Access-denied-for-user-‘debezium‘-’-’-to-database-‘inventory’"><a href="#ERROR-1044-42000-Access-denied-for-user-‘debezium‘-’-’-to-database-‘inventory’" class="headerlink" title="ERROR 1044 (42000): Access denied for user ‘debezium‘@’%’ to database ‘inventory’"></a>ERROR 1044 (42000): Access denied for user ‘debezium‘@’%’ to database ‘inventory’</h3><p>‘’’<br>GRANT ALL PRIVILEGES ON <em>.</em> TO ‘debezium@localhost’ WITH GRANT OPTION;<br>‘’’</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-pulsar-Debezium-CDC-测试" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/04/10/pulsar-Debezium-CDC-测试/" class="article-date">
      <time datetime="2019-04-10T02:39:19.000Z" itemprop="datePublished">2019-04-10</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/10/pulsar-Debezium-CDC-测试/">pulsar Debezium CDC 测试</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h2 id="结果验证"><a href="#结果验证" class="headerlink" title="结果验证"></a>结果验证</h2><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2>
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-系统架构和设计理念" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/04/01/系统架构和设计理念/" class="article-date">
      <time datetime="2019-04-01T02:34:25.000Z" itemprop="datePublished">2019-04-01</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/01/系统架构和设计理念/">Pulsar系统架构和设计理念</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="Pulsar-的分层架构"><a href="#Pulsar-的分层架构" class="headerlink" title="Pulsar 的分层架构"></a>Pulsar 的分层架构</h2><p>Apache Pulsar 和其他消息系统最根本的不同是采用分层架构。<br>Apache Pulsar 集群由两层组成：无状态服务层，由一组接收和传递消息的 Broker 组成；<br>以及一个有状态持久层，由一组名为 bookies 的 Apache BookKeeper 存储节点组成，可持久化地存储消息。<br>下图显示了 Apache Pulsar 的典型部署。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae77279003.png" width="800"></div>

<p>在 Pulsar 客户端中提供生产者和消费者（Producer &amp; Consumer）接口，应用程序使用 Pulsar 客户端连接到 Broker 来发布和消费消息。</p>
<p>Pulsar 客户端不直接与存储层 Apache BookKeeper 交互。<br>客户端也没有直接的 BookKeeper 访问权限。这种隔离，为 Pulsar 实现安全的多租户统一身份验证模型提供了基础。</p>
<p>Apache Pulsar 为客户端提供多种语言的支持，包括 Java，C ++，Python，Go 和 Websockets。<br>Apache Pulsar 还提供了一组兼容 Kafka 的 API，用户可以通过简单地更新依赖关系并将客户端指向 Pulsar 集群来迁移现有的 Kafka 应用程序，这样现有的 Kafka 应用程序可以立即与 Apache Pulsar 一起使用，无需更改任何代码。</p>
<h3 id="Broker-层：无状态服务层"><a href="#Broker-层：无状态服务层" class="headerlink" title="Broker 层：无状态服务层"></a>Broker 层：无状态服务层</h3><p>Broker 集群在 Apache Pulsar 中形成无状态服务层。服务层是“无状态的”，因为 Broker 实际上并不在本地存储任何消息数据。<br>有关 Pulsar 主题的消息，都被存储在分布式日志存储系统（Apache BookKeeper）中。我们将在下一节中更多地讨论 BookKeeper。</p>
<p>每个主题分区（Topic Partition）由 Pulsar 分配给某个 Broker，该 Broker 称为该主题分区的所有者。<br>Pulsar 生产者和消费者连接到主题分区的所有者 Broker，以向所有者代理发送消息并消费消息。</p>
<p>如果一个 Broker 失败，Pulsar 会自动将其拥有的主题分区移动到群集中剩余的某一个可用 Broker 中。<br>这里要说的一件事是：由于 Broker 是无状态的，当发生 Topic 的迁移时，Pulsar 只是将所有权从一个 Broker 转移到另一个 Broker，在这个过程中，不会有任何数据复制发生。</p>
<p>下图显示了一个拥有 4 个 Broker 的 Pulsar 集群，其中 4 个主题分区分布在 4 个 Broker 中。<br>每个 Broker 拥有并为一个主题分区提供消息服务。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae7730951f.png" width="800"></div>

<h3 id="BookKeeper-层：持久化存储层"><a href="#BookKeeper-层：持久化存储层" class="headerlink" title="BookKeeper 层：持久化存储层"></a>BookKeeper 层：持久化存储层</h3><p>Apache BookKeeper 是 Apache Pulsar 的持久化存储层。<br>Apache Pulsar 中的每个主题分区本质上都是存储在 Apache BookKeeper 中的分布式日志。</p>
<p>每个分布式日志又被分为 Segment 分段。<br>每个 Segment 分段作为 Apache BookKeeper 中的一个 Ledger，均匀分布并存储在 BookKeeper 群集中的多个 Bookie（Apache BookKeeper 的存储节点）中。<br>Segment 的创建时机包括以下几种：<br>基于配置的 Segment 大小；<br>基于配置的滚动时间；<br>或者当 Segment 的所有者被切换。<br>通过 Segment 分段的方式，主题分区中的消息可以均匀和平衡地分布在群集中的所有 Bookie 中。<br>这意味着主题分区的大小不仅受一个节点容量的限制；<br>相反，它可以扩展到整个 BookKeeper 集群的总容量。</p>
<p>下面的图说明了一个分为 x 个 Segment 段的主题分区。<br>每个 Segment 段存储 3 个副本。<br>所有 Segment 都分布并存储在 4 个 Bookie 中。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae772bb849.png" width="800"></div>

<h4 id="Segment-为中心的存储"><a href="#Segment-为中心的存储" class="headerlink" title="Segment 为中心的存储"></a>Segment 为中心的存储</h4><p>存储服务的分层的架构 和 以 Segment 为中心的存储 是 Apache Pulsar（使用 Apache BookKeeper）的两个关键设计理念。<br>这两个基础为 Pulsar 提供了许多重要的好处：</p>
<ul>
<li>无限制的主题分区存储</li>
<li>即时扩展，无需数据迁移<ol>
<li>无缝 Broker 故障恢复</li>
<li>无缝集群扩展</li>
<li>无缝的存储（Bookie）故障恢复</li>
</ol>
</li>
<li>独立的可扩展性</li>
</ul>
<p>下面我们分别展开来看这几个好处。</p>
<h5 id="无限制的主题分区存储"><a href="#无限制的主题分区存储" class="headerlink" title="无限制的主题分区存储"></a>无限制的主题分区存储</h5><p>由于主题分区被分割成 Segment 并在 Apache BookKeeper 中以分布式方式存储，因此主题分区的容量不受任何单一节点容量的限制。<br>相反，主题分区可以扩展到整个 BookKeeper 集群的总容量，只需添加 Bookie 节点即可扩展集群容量。<br>这是 Apache Pulsar 支持存储无限大小的流数据，并能够以高效，分布式方式处理数据的关键。<br>使用 Apache BookKeeper 的分布式日志存储，对于统一消息服务和存储至关重要。</p>
<h5 id="即时扩展，无需数据迁移"><a href="#即时扩展，无需数据迁移" class="headerlink" title="即时扩展，无需数据迁移"></a>即时扩展，无需数据迁移</h5><p>由于消息服务和消息存储分为两层，因此将主题分区从一个 Broker 移动到另一个 Broker 几乎可以瞬时内完成，而无需任何数据重新平衡（将数据从一个节点重新复制到另一个节点）。<br>这一特性对于高可用的许多方面至关重要，例如集群扩展；对 Broker 和 Bookie 失败的快速应对。 </p>
<h6 id="无缝-Broker-故障恢复"><a href="#无缝-Broker-故障恢复" class="headerlink" title="无缝 Broker 故障恢复"></a>无缝 Broker 故障恢复</h6><p>下图说明了 Pulsar 如何处理 Broker 失败的示例。<br>在例子中 Broker 2 因某种原因（例如停电）而断开。<br>Pulsar 检测到 Broker 2 已关闭，并立即将 Topic1-Part2 的所有权从 Broker 2 转移到 Broker 3。<br>在 Pulsar 中数据存储和数据服务分离，所以当代理 3 接管 Topic1-Part2 的所有权时，它不需要复制 Partiton 的数据。<br>如果有新数据到来，它立即附加并存储为 Topic1-Part2 中的 Segment x + 1。<br>Segment x + 1 被分发并存储在 Bookie1, 2 和 4 上。因为它不需要重新复制数据，所以所有权转移立即发生而不会牺牲主题分区的可用性。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae77366fe5.png" width="800"></div>

<h6 id="无缝集群容量扩展"><a href="#无缝集群容量扩展" class="headerlink" title="无缝集群容量扩展"></a>无缝集群容量扩展</h6><p>下图说明了 Pulsar 如何处理集群的容量扩展。<br>当 Broker 2 将消息写入 Topic1-Part2 的 Segment X 时，将 Bookie X 和 Bookie Y 添加到集群中。<br>Broker 2 立即发现新加入的 Bookies X 和 Y。然后 Broker 将尝试将 Segment X + 1 和 X + 2 的消息存储到新添加的 Bookie 中。<br>新增加的 Bookie 立刻被使用起来，流量立即增加，而不会重新复制任何数据。<br>除了机架感知和区域感知策略之外，Apache BookKeeper 还提供资源感知的放置策略，以确保流量在群集中的所有存储节点之间保持平衡。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae7747779e.png" width="800"></div>

<h6 id="无缝的存储（Bookie）故障恢复"><a href="#无缝的存储（Bookie）故障恢复" class="headerlink" title="无缝的存储（Bookie）故障恢复"></a>无缝的存储（Bookie）故障恢复</h6><p>下图说明了 Pulsar（通过 Apache BookKeeper）如何处理 bookie 的磁盘故障。<br>这里有一个磁盘故障导致存储在 bookie 2 上的 Segment 4 被破坏。<br>Apache BookKeeper 后台会检测到这个错误并进行复制修复。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae773e0cd5.png" width="800"></div>

<p>Apache BookKeeper 中的副本修复是 Segment（甚至是 Entry）级别的多对多快速修复，这比重新复制整个主题分区要精细，只会复制必须的数据。<br>这意味着 Apache BookKeeper 可以从 bookie 3 和 bookie 4 读取 Segment 4 中的消息，并在 bookie 1 处修复 Segment 4。<br>所有的副本修复都在后台进行，对 Broker 和应用透明。<br>即使有 Bookie 节点出错的情况发生时，通过添加新的可用的 Bookie 来替换失败的 Bookie，所有 Broker 都可以继续接受写入，而不会牺牲主题分区的可用性。</p>
<h5 id="独立的可扩展性"><a href="#独立的可扩展性" class="headerlink" title="独立的可扩展性"></a>独立的可扩展性</h5><p>由于消息服务层和持久存储层是分开的，因此 Apache Pulsar 可以独立地扩展存储层和服务层。这种独立的扩展，更具成本效益：</p>
<ul>
<li><p>当您需要支持更多的消费者或生产者时，您可以简单地添加更多的 Broker。<br>主题分区将立即在 Brokers 中做平衡迁移，一些主题分区的所有权立即转移到新的 Broker。</p>
</li>
<li><p>当您需要更多存储空间来将消息保存更长时间时，您只需添加更多 Bookie。<br>通过智能资源感知和数据放置，流量将自动切换到新的 Bookie 中。<br>Apache Pulsar 中不会涉及到不必要的数据搬迁，不会将旧数据从现有存储节点重新复制到新存储节点。</p>
<h2 id="Pulsar-VS-Kafka"><a href="#Pulsar-VS-Kafka" class="headerlink" title="Pulsar VS. Kafka"></a>Pulsar VS. Kafka</h2><p>Apache Kafka 和 Apache Pulsar 都有类似的消息概念。<br>客户端通过主题与消息系统进行交互。 每个主题都可以分为多个分区。<br>然而，Apache Pulsar 和 Apache Kafka 之间的根本区别在于 Apache Kafka 是以分区为存储中心，而 Apache Pulsar 是以 Segment 为存储中心。</p>
<div align="center"><img src="/2019/04/01/系统架构和设计理念/5beae774be269.png" width="800"></div>

</li>
</ul>
<p>上图显示了以分区为中心和以 Segment 为中心的系统之间的差异。</p>
<h3 id="Apache-Kafka"><a href="#Apache-Kafka" class="headerlink" title="Apache Kafka"></a>Apache Kafka</h3><p>在 Apache Kafka 中，分区只能存储在单个节点上并复制到其他节点，其容量受最小节点容量的限制。<br>这意味着容量扩展需要对分区重新平衡，这反过来又需要重新复制整个分区，以平衡新添加的代理的数据和流量。</p>
<p>重新传输数据非常昂贵且容易出错，并且会消耗网络带宽和 I/O。维护人员在执行此操作时必须非常小心，以避免破坏生产系统。</p>
<p>Kafka 中分区数据的重新拷贝不仅发生在以分区为中心的系统中的群集扩展上。<br>许多其他事情也会触发数据重新拷贝，例如副本故障，磁盘故障或计算机的故障。在数据重新复制期间，分区通常不可用，直到数据重新复制完成。<br>例如，如果您将分区配置为存储为 3 个副本，这时，如果丢失了一个副本，则必须重新复制完整个分区后，分区才可以再次可用。</p>
<p>Kafka 中分区数据的重新拷贝不仅发生在以分区为中心的系统中的群集扩展上。<br>许多其他事情也会触发数据重新拷贝，例如副本故障，磁盘故障或计算机的故障。在数据重新复制期间，分区通常不可用，直到数据重新复制完成。<br>例如，如果您将分区配置为存储为 3 个副本，这时，如果丢失了一个副本，则必须重新复制完整个分区后，分区才可以再次可用。</p>
<p>在用户遇到故障之前，通常会忽略这种缺陷，因为许多情况下，在短时间内仅是对内存中缓存数据的读取。<br>当数据被保存到磁盘后，用户将越来越多地不可避免地遇到数据丢失，故障恢复的问题，特别是在需要将数据长时间保存的场合。</p>
<h3 id="Apache-Pulsar"><a href="#Apache-Pulsar" class="headerlink" title="Apache Pulsar"></a>Apache Pulsar</h3><p>相反，在 Apache Pulsar 中，同样是以分区为逻辑单元，但是以 Segment 为物理存储单元。<br>分区随着时间的推移会进行分段，并在整个集群中均衡分布，旨在有效地迅速地扩展。</p>
<p>Pulsar 是以 Segment 为中心的，因此在扩展容量时不需要数据重新平衡和拷贝，旧数据不会被重新复制，这要归功于在 Apache BookKeeper 中使用可扩展的以 Segment 为中心的分布式日志存储系统。</p>
<p>通过利用分布式日志存储，Pulsar 可以最大化 Segment 放置选项，实现高写入和高读取可用性。<br>例如，使用 BookKeeper，副本设置等于 2，只要任何 2 个 Bookie 启动，就可以对主题分区进行写入。<br>对于读取可用性，只要主题分区的副本集中有 1 个处于活动状态，用户就可以读取它，而不会出现任何不一致。</p>
<p>总之，Apache Pulsar 这种独特的基于分布式日志存储的以 Segment 为中心的发布 / 订阅消息系统可以提供许多优势，例如可靠的流式系统，包括无限制的日志存储，无需分区重新平衡的即时扩展，快速复制修复以及通过最大化数据放置实现高写入和读取可用性选项。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-消息中间件pulsar，选型与评测" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/03/29/消息中间件pulsar，选型与评测/" class="article-date">
      <time datetime="2019-03-29T02:34:57.000Z" itemprop="datePublished">2019-03-29</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/29/消息中间件pulsar，选型与评测/">消息中间件pulsar选型记录</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>我们在选择中间件的过程，主要从两个方面考虑：</p>
<ul>
<li>中间件能否满足我的业务系统的场景，并且随着业务系统的发展，最好能一直满足场景的需要。</li>
<li>性能指标、稳定性、运维能力附属配套是否完善<br>消息中间件的选型过程我们也从这两个角度考虑。<h2 id="业务场景的支持能力"><a href="#业务场景的支持能力" class="headerlink" title="业务场景的支持能力"></a>业务场景的支持能力</h2>对于消息系统，消息模型是首先考虑的事情。消息模型应涵盖以下 3 个方面：</li>
<li>消息消费——如何发送和消费消息；</li>
</ul>
<ul>
<li>消息确认（ack）——如何确认消息；</li>
</ul>
<ul>
<li>消息保存——消息保留多长时间，触发消息删除的原因以及怎样删除；<h3 id="消息消费模型"><a href="#消息消费模型" class="headerlink" title="消息消费模型"></a>消息消费模型</h3>消息传递可以分为两类：队列（Queue）和流（Stream）。<h4 id="队列（Queue）模型"><a href="#队列（Queue）模型" class="headerlink" title="队列（Queue）模型"></a>队列（Queue）模型</h4>队列模型主要是采用无序或者共享的方式来消费消息。通过队列模型，用户可以创建多个消费者从单个管道中接收消息；<br>当一条消息从队列发送出来后，多个消费者中的只有一个（任何一个都有可能）接收和消费这条消息。<br>消息系统的具体实现决定了最终哪个消费者实际接收到消息。<br>队列模型通常与无状态应用程序一起结合使用。<br>无状态应用程序不关心排序，但它们确实需要能够确认（ack）或删除单条消息，以及尽可能地扩展消费并行性的能力。<br>典型的基于队列模型的消息系统包括 RabbitMQ 和 RocketMQ。<h4 id="流式（Stream）模型"><a href="#流式（Stream）模型" class="headerlink" title="流式（Stream）模型"></a>流式（Stream）模型</h4>相比之下，流模型要求消息的消费严格排序或独占消息消费。<br>对于一个管道，使用流式模型，始终只会有一个消费者使用和消费消息。<br>消费者按照消息写入管道的确切顺序接收从管道发送的消息。<br>流模型通常与有状态应用程序相关联。有状态的应用程序更加关注消息的顺序及其状态。<br>消息的消费顺序决定了有状态应用程序的状态。消息的顺序将影响应用程序处理逻辑的正确性。<br>在面向微服务或事件驱动的体系结构中，队列模型和流模型都是必需的。<h4 id="Pulsar-的消息消费模型"><a href="#Pulsar-的消息消费模型" class="headerlink" title="Pulsar 的消息消费模型"></a>Pulsar 的消息消费模型</h4>Apache Pulsar 通过“订阅”，抽象出了统一的: producer-topic-subscription-consumer 消费模型。<br>Pulsar 的消息模型既支持队列模型，也支持流模型。<br>在 Pulsar 的消息消费模型中，Topic 是用于发送消息的通道。<br>每一个 Topic 对应着 Apache BookKeeper 中的一个分布式日志。<br>发布者发布的每条消息只在 Topic 中存储一次；存储的过程中，BookKeeper 会将消息复制存储在多个存储节点上；<br>Topic 中的每条消息，可以根据消费者的订阅需求（subscription），多次被使用，每个订阅对应一个消费者组（Consumer Group）。<br>主题（Topic）是消费消息的真实来源。尽管消息仅在主题（Topic）上存储一次，但是用户可以有不同的订阅方式（subscription）来消费这些消息：</li>
<li>消费者被组合在一起消费消息，每个消费组是一个订阅（subscription）。</li>
<li>每个 Topic 可以有不同的消费组（subscription）。</li>
<li>每组消费者都是对主题的一个订阅。</li>
<li>每组消费者可以拥有自己不同的消费方式： 独占（Exclusive），故障切换（Failover）或共享（Share）。<br>Pulsar 通过这种模型，将队列模型和流模型这两种模型结合在了一起，提供了统一的 API 接口。<br>这种模型，既不会影响消息系统的性能，也不会带来额外的开销，同时还为用户提供了更多灵活性，方便用户程序以最匹配模式来使用消息系统。<h5 id="独占订阅（Stream-流模型）"><a href="#独占订阅（Stream-流模型）" class="headerlink" title="独占订阅（Stream 流模型）"></a>独占订阅（Stream 流模型）</h5>独占订阅中，在任何时间，一个消费者组（订阅）中有且只有一个消费者来消费 Topic 中的消息。<br>下图是独占订阅的示例。<br>在这个示例中有一个有订阅 A 的活跃消费者 A-0，消息 m0 到 m4 按顺序传送并由 A-0 消费。<br>如果另一个消费者 A-1 想要附加到订阅 A，则是不被允许的。<br><div align="center"><img src="/2019/03/29/消息中间件pulsar，选型与评测/5beae5e79a80e.png" width="800"></div><h5 id="故障切换（Stream-流模型）"><a href="#故障切换（Stream-流模型）" class="headerlink" title="故障切换（Stream 流模型）"></a>故障切换（Stream 流模型）</h5>故障切换订阅，多个消费者（Consumer）可以附加到同一订阅。<br>但是，一个订阅中的所有消费者，只会有一个消费者被选为该订阅的主消费者。 其他消费者将被指定为故障转移消费者。<br>当主消费者断开连接时，分区将被重新分配给其中一个故障转移消费者，而新分配的消费者将成为新的主消费者。<br>发生这种情况时，所有未确认（ack）的消息都将传递给新的主消费者。 这类似于 Apache Kafka 中的 Consumer partition rebalance。<br>下图是故障切换订阅的示例。<br>消费者 B-0 和 B-1 通过订阅 B 订阅消费消息。B-0 是主消费者并接收所有消息。<br>B-1 是故障转移消费者，如果消费者 B-0 出现故障，它将接管消费。</li>
</ul>
<p><div align="center"><img src="/2019/03/29/消息中间件pulsar，选型与评测/5beae6144d6c4.png" width="800"></div></p>
<h5 id="共享订阅（Queue-队列模型）"><a href="#共享订阅（Queue-队列模型）" class="headerlink" title="共享订阅（Queue 队列模型）"></a>共享订阅（Queue 队列模型）</h5><p>使用共享订阅，在同一个订阅背后，用户按照应用的需求挂载任意多的消费者。<br>订阅中的所有消息以循环分发形式发送给订阅背后的多个消费者，并且一个消息仅传递给一个消费者。<br>当消费者断开连接时，所有传递给它但是未被确认（ack）的消息将被重新分配和组织，以便发送给该订阅上剩余的剩余消费者。<br>下图是共享订阅的示例。 消费者 C-1，C-2 和 C-3 都在同一主题上消费消息。 每个消费者接收大约所有消息的 1/3。<br>如果想提高消费的速度，用户不需要不增加分区数量，只需要在同一个订阅中添加更多的消费者。</p>
<p><div align="center"><img src="/2019/03/29/消息中间件pulsar，选型与评测/5beae63bd47f8.png" width="800"></div><br><strong>三种订阅模式的选择</strong><br>独占和故障切换订阅，仅允许一个消费者来使用和消费每个对主题的订阅。<br>这两种模式都按主题分区顺序使用消息。它们最适用于需要严格消息顺序的流（Stream）用例。</p>
<p>共享订阅允许每个主题分区有多个消费者。同一订阅中的每个消费者仅接收主题分区的一部分消息。<br>共享订阅最适用于不需要保证消息顺序的队列（Queue）的使用模式，并且可以按照需要任意扩展消费者的数量。</p>
<p>Pulsar 中的订阅实际上与 Apache Kafka 中的 Consumer Group 的概念类似。<br>创建订阅的操作很轻量化，而且具有高度可扩展性，用户可以根据应用的需要创建任意数量的订阅。<br>对同一主题的不同订阅，也可以采用不同的订阅类型。比如用户可以在同一主题上可以提供一个包含 3 个消费者的故障切换订阅，同时也提供一个包含 20 个消费者的共享订阅，并且可以在不改变分区数量的情况下，向共享订阅添加更多的消费者。<br>下图描绘了一个包含 3 个订阅 A，B 和 C 的主题，并说明了消息如何从生产者流向消费者。</p>
<p><div align="center"><img src="/2019/03/29/消息中间件pulsar，选型与评测/5beae6853d2ae.png" width="800"></div><br>除了统一消息 API 之外，由于 Pulsar 主题分区实际上是存储在 Apache BookKeeper 中，它还提供了一个读取 API（Reader），类似于消费者 API（但 Reader 没有游标管理），以便用户完全控制如何使用 Topic 中的消息。</p>
<h3 id="Pulsar-的消息确认（ACK）"><a href="#Pulsar-的消息确认（ACK）" class="headerlink" title="Pulsar 的消息确认（ACK）"></a>Pulsar 的消息确认（ACK）</h3><p>由于分布式系统的特性，当使用分布式消息系统时，可能会发生故障。<br>比如在消费者从消息系统中的主题消费消息的过程中，消费消息的消费者和服务于主题分区的消息代理（Broker）都可能发生错误。<br>消息确认（ACK）的目的就是保证当发生这样的故障后，消费者能够从上一次停止的地方恢复消费，保证既不会丢失消息，也不会重复处理已经确认（ACK）的消息。</p>
<p>在 Apache Kafka 中，恢复点通常称为 Offset，更新恢复点的过程称为消息确认或提交 Offset。<br>在 Apache Pulsar 中，每个<strong>订阅中</strong>都使用一个专门的数据结构–游标（Cursor）来跟踪订阅中的每条消息的确认（ACK）状态。<br>每当消费者在主题分区上确认消息时，游标都会更新。更新游标可确保消费者不会再次收到消息。</p>
<p>Apache Pulsar 提供两种消息确认方法，单条确认（Individual Ack）和累积确认（Cumulative Ack）。<br>通过累积确认，消费者只需要确认它收到的最后一条消息。主题分区中的所有消息（包括）提供消息 ID 将被标记为已确认，并且不会再次传递给消费者。累积确认与 Apache Kafka 中的 Offset 更新类似。</p>
<p>Apache Pulsar 可以支持消息的单条确认，也就是选择性确认。消费者可以单独确认一条消息。 被确认后的消息将不会被重新传递。</p>
<p>下图说明了单条确认和累积确认的差异（灰色框中的消息被确认并且不会被重新传递）。在图的上半部分，它显示了累计确认的一个例子，M12 之前的消息被标记为 acked。在图的下半部分，它显示了单独进行 acking 的示例。仅确认消息 M7 和 M12 - 在消费者失败的情况下，除了 M7 和 M12 之外，其他所有消息将被重新传送。</p>
<p><div align="center"><img src="/2019/03/29/消息中间件pulsar，选型与评测/5beae6b6e2ac0.png" width="800"></div><br><strong>独占订阅或故障切换订阅</strong>的消费者能够对消息进行单条确认和累积确认；<br>共享订阅的消费者只允许对消息进行单条确认。单条确认消息的能力为处理消费者故障提供了更好的体验。<br>对于某些应用来说，处理一条消息可能需要很长时间或者非常昂贵，防止重新传送已经确认的消息非常重要。</p>
<p>这个管理 Ack 的专门的数据结构–游标（Cursor），由 Broker 来管理，利用 BookKeeper 的 Ledger 提供存储，在后面的文章中我们会介绍更多的关于游标（Cursor）的细节。</p>
<p>Apache Pulsar 提供了灵活的消息消费订阅类型和消息确认方法，通过简单的统一的 API，就可以支持各种消息和流的使用场景。</p>
<h3 id="Pulsar-的消息保留（Retention）"><a href="#Pulsar-的消息保留（Retention）" class="headerlink" title="Pulsar 的消息保留（Retention）"></a>Pulsar 的消息保留（Retention）</h3><p>在消息被确认后，Pulsar 的 Broker 会更新对应的游标。当 Topic 里面中的一条消息，被<strong>所有的订阅都确认 ack </strong>后，才能删除这条消息。<br>Pulsar 还允许通过设置保留时间，将消息保留更长时间，即使所有订阅已经确认消费了它们。</p>
<p>下图说明了如何在有 2 个订阅的主题中保留消息。<br>订阅 A 在 M6 和订阅 B 已经消耗了 M10 之前的所有消息之前已经消耗了所有消息。这意味着 M6 之前的所有消息（灰色框中）都可以安全删除。<br>订阅 A 仍未使用 M6 和 M9 之间的消息，无法删除它们。如果主题配置了消息保留期，则消息 M0 到 M5 将在配置的时间段内保持不变，即使 A 和 B 已经确认消费了它们。</p>
<p><div align="center"><img src="/2019/03/29/消息中间件pulsar，选型与评测/5beae6f4a9ee3.png" width="800"></div><br>在消息保留策略中，Pulsar 还支持消息生存时间（TTL）。<br>如果消息未在配置的 TTL 时间段内被任何消费者使用，则消息将自动标记为已确认。<br> 消息保留期消息 TTL 之间的区别在于：<strong>消息保留期作用于标记为已确认并设置为已删除的消息，而 TTL 作用于未 ack 的消息</strong>。<br> 上面的图例中说明了 Pulsar 中的 TTL。 例如，如果订阅 B 没有活动消费者，则在配置的 TTL 时间段过后，消息 M10 将自动标记为已确认，即使没有消费者实际读取该消息。</p>
<h3 id="Pulsar-VS-Kafka"><a href="#Pulsar-VS-Kafka" class="headerlink" title="Pulsar VS. Kafka"></a>Pulsar VS. Kafka</h3><p>通过以上几个方面，我们对 Pulsar 和 Kafka 在消息模型方面的不同点进行一个总结。</p>
<p>模型概念<br>Kafka： Producer - topic - consumer group - consumer；</p>
<p>Pulsar：Producer - topic - subscription - consumer。</p>
<p>消费模式<br>Kafka： 主要集中在流（Stream）模式，对单个 partition 是独占消费，没有共享（Queue）的消费模式；</p>
<p>Pulsar：提供了统一的消息模型和 API。流（Stream）模式 – 独占和故障切换订阅方式；队列（Queue）模式 – 共享订阅的方式。</p>
<p>消息确认（Ack）<br>Kafka： 使用偏移 Offset；</p>
<p>Pulsar：使用专门的 Cursor 管理。累积确认和 Kafka 效果一样；提供单条或选择性确认。</p>
<p>消息保留<br>Kafka：根据设置的保留期来删除消息。有可能消息没被消费，过期后被删除。 不支持 TTL。</p>
<p>Pulsar：消息只有被所有订阅消费后才会删除，不会丢失数据。也允许设置保留期，保留被消费的数据。支持 TTL。</p>
<p>对比总结<br>Apache Pulsar 将高性能的流（Apache Kafka 所追求的）和灵活的传统队列（RabbitMQ 所追求的）结合到一个统一的消息模型和 API 中。<br>Pulsar 使用统一的 API 为用户提供一个支持流和队列的系统，且具有同样的高性能。程序可以将此统一的 API 用于高性能队列和流式传输，而无需维护两套系统：RabbitMQ 进行队列处理，Kafka 进行流式处理。  </p>
<h2 id="性能指标、稳定性、运维能力"><a href="#性能指标、稳定性、运维能力" class="headerlink" title="性能指标、稳定性、运维能力"></a>性能指标、稳定性、运维能力</h2><h3 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h3><h4 id="1-Producer只生产，发送速率逐步变大"><a href="#1-Producer只生产，发送速率逐步变大" class="headerlink" title="1.    Producer只生产，发送速率逐步变大"></a>1.    Producer只生产，发送速率逐步变大</h4><ul>
<li>发送的1000B的消息包，在每秒发送大于100000笔的场景中，由于Broker需要同时持久化两份消息到Bookie中，在吞吐量到达千兆网卡的的上限之前吞吐量逐渐增大。</li>
<li>在到达千兆网卡的上限之后，随着发送频率增大，时延延长，实际的发送吞吐量也不再增高。<h4 id="2-Producer只生产，分区逐步增多"><a href="#2-Producer只生产，分区逐步增多" class="headerlink" title="2.    Producer只生产，分区逐步增多"></a>2.    Producer只生产，分区逐步增多</h4></li>
<li>分区能起到负载均衡提高吞吐量的作用。</li>
<li>在3个Broker和3个分区的情况下，消息的分配比例关系约为2：1：1。为什么不是1：1：1，分配比例的算法需要进一步研究和测试。</li>
<li>当分区的数目超过100后，发送速率迅速下降，还需进一步测试和研究。<h4 id="3-Producer只生产，主题逐步增多"><a href="#3-Producer只生产，主题逐步增多" class="headerlink" title="3.    Producer只生产，主题逐步增多"></a>3.    Producer只生产，主题逐步增多</h4></li>
<li>随着topic数目增多，主题均匀的分配到每一个Broker</li>
<li>主题的分配比例为3个Broker，3个主题的情况下，每个Broker分配到一个主题。</li>
<li>客户端在主题数目大于10个的时候，直接内存溢出。<h4 id="4-Producer只生产，消息逐渐变大"><a href="#4-Producer只生产，消息逐渐变大" class="headerlink" title="4.    Producer只生产，消息逐渐变大"></a>4.    Producer只生产，消息逐渐变大</h4></li>
<li>在没有到达硬件资源约束的情况下，系统对各种消息的大小，吞吐量均衡。<h4 id="5-Producer只生产，压缩方式对比"><a href="#5-Producer只生产，压缩方式对比" class="headerlink" title="5.    Producer只生产，压缩方式对比"></a>5.    Producer只生产，压缩方式对比</h4></li>
<li>采用压缩方式后，可以有效的节省网络带宽。</li>
<li>压缩率为（39/800000）/（920/100000）=5/1000</li>
<li>增加客户端的cpu使用率。客户端使用率到达70%的时候，发送速率不在提升，一直保持在800000笔左右。</li>
<li>LZ4 的压缩方式比ZLIB更节省cpu的运算资源，因此推荐使用LZ4。<h4 id="6-Producer只生产，Bookie-数量、写入数量、确认数量对比"><a href="#6-Producer只生产，Bookie-数量、写入数量、确认数量对比" class="headerlink" title="6.    Producer只生产，Bookie 数量、写入数量、确认数量对比"></a>6.    Producer只生产，Bookie 数量、写入数量、确认数量对比</h4></li>
<li>EnsembleSize=1; WriteQuorum=1; AckQuorum=1 时延：3.79<br>第一种场景，没有达到网卡的带宽的约束，因此时延比较低。</li>
<li>EnsembleSize=2; WriteQuorum=2; AckQuorum=1 时延：4.58<br>第二种场景，对比第一种场景，增加了一个写入，因此时延有所增加，但是在合理范围</li>
<li>EnsembleSize=3; WriteQuorum=2; AckQuorum=1 时延：4.06<br>第三种场景，对比第二种场景，增加了一个的Bookie，时延有所降低。</li>
<li>EnsembleSize=3; WriteQuorum=2; AckQuorum=2 时延：79<br>第四种场景，对比第三种场景，由于写入确认数目增加，导致时延延长，但是在合理范围。<h4 id="7-Producer只生产，同步刷盘与异步刷盘"><a href="#7-Producer只生产，同步刷盘与异步刷盘" class="headerlink" title="7.    Producer只生产，同步刷盘与异步刷盘"></a>7.    Producer只生产，同步刷盘与异步刷盘</h4></li>
<li>在没有达到网络带宽上限的情况下，同步刷盘，与异步刷盘，时延差距不大。</li>
<li>在到达网络带宽的情况下，同步刷屏优于异步刷盘。<h4 id="8-Producer只生产，发送批次时间窗口"><a href="#8-Producer只生产，发送批次时间窗口" class="headerlink" title="8.    Producer只生产，发送批次时间窗口"></a>8.    Producer只生产，发送批次时间窗口</h4></li>
<li>发送批次时间窗口值扩大，导致发送的不均匀，增加了时延，建议采用默认值。<h4 id="9-Producer只生产，单生产者与多生产者"><a href="#9-Producer只生产，单生产者与多生产者" class="headerlink" title="9.    Producer只生产，单生产者与多生产者"></a>9.    Producer只生产，单生产者与多生产者</h4></li>
<li>多个生产者，吞吐量变化平稳，时延平稳</li>
<li>没有采用压缩算法的情况，单个客户端生产者数量增多，会导致客户端直接内存溢出。<h4 id="10-Producer（集成部署、分开部署）"><a href="#10-Producer（集成部署、分开部署）" class="headerlink" title="10.    Producer（集成部署、分开部署）"></a>10.    Producer（集成部署、分开部署）</h4></li>
<li>集成部署和分开部署，在没有到达资源约束的情况下（网卡带宽约束），时延和吞吐量基本一直。</li>
<li>在到达资源约束rate=100000的情况下，集成部署往Broker所在的Bookie写一份数据，而分开部署的Broker，需要同时往两个不同的Bookie的机器上，写相同的数据，导致Broker的出口网络带宽，到达上限，因此集成部署比分开部署时延低些。<h4 id="11-Producer生产和Consumer消费同时进行"><a href="#11-Producer生产和Consumer消费同时进行" class="headerlink" title="11.    Producer生产和Consumer消费同时进行"></a>11.    Producer生产和Consumer消费同时进行</h4></li>
<li>生产与消费同时进行，生产者的时延会延长，但是生产的速率不变</li>
<li>同时开启生产者和消费者的消费速度，比只开启消费者消费堆积消息速率低</li>
<li>对于同一主题，生产者和消费者，同时分配到一个Broker上，因此该主机的网卡出现瓶颈，一部分带宽被消费者占用，一部分带宽被Bookie写给另外一个Bookie。因此计划补充设计带宽没有打满的场景<h4 id="13-Consumer消费堆积消息"><a href="#13-Consumer消费堆积消息" class="headerlink" title="13.    Consumer消费堆积消息"></a>13.    Consumer消费堆积消息</h4></li>
<li>合并部署在消费堆积消息的时候，由于有一部分数据是在本地硬盘上，不用通过网络去其它的主机上取，所以，读取效率会比分开部署快5%左右。<h3 id="破坏性测试"><a href="#破坏性测试" class="headerlink" title="破坏性测试"></a>破坏性测试</h3></li>
<li>杀死消息的Broker场景中，消息没有丢失、没有重复、没有顺序的问题。</li>
<li>杀死两个Bookie中的一个Bookie的场景中，消息没有丢失、没有重复、没有顺序的问题。</li>
<li>隔离Broker与Zookeeper同时没有开启消除重复配置的场景中，Broker发现无法与Zookeeper通信，会重新启动自己，并且会分配新的Broker，此种场景消息没有丢失、没有顺序问题，但是出现消息重复的现象。</li>
<li>隔离Broker与Zookeeper同时开启消除重复配置的场景中，消息没有丢失、没有顺序问题，没有消息重复的问题。</li>
<li>隔离Bookie与Zookeeper的场景，消息没有丢失、没有重复、没有顺序的问题。</li>
<li>杀死3个Bookie中的其中2个Bookie，消息没有丢失、没有重复、没有顺序的问题。</li>
<li>杀死2个Bookie中的所有的2Bookie，消息没有重复、没有顺序问题，但是出现消息丢失现象，重新启动杀死的2个Bookie中的其中的1个Bookie，消息可以重新读取。<h3 id="指标监控"><a href="#指标监控" class="headerlink" title="指标监控"></a>指标监控</h3></li>
<li>Pulsar提供了丰富的监控指标输出指标。</li>
<li>可以容易的与prometheus监控平台对接，采集其监控指标，通过grafana进行图形展现。过程简单有效，因此推荐此种方式进行监控。<h3 id="运维能力"><a href="#运维能力" class="headerlink" title="运维能力"></a>运维能力</h3></li>
<li>功能测试目的是从运维和管理的角度进行功能测试，Pulsar的管理维度，分成全局集群、区域集群、租户、命名空间、主题、持久化和非持久化等维度进（见下图）。我们针对以上（除了全局集群）维度进行重点功能的测试。Pulsar提供了命令行命令方式、管理客户端方式、管理URL方式，三种方式进行功能管理，管理命令丰富，满足Pulsar集群的日常管理的需要。如果单集群的部署情况下，建议使用默认的命令行管理方式进行管理。<br><img src="/2019/03/29/消息中间件pulsar，选型与评测/jumb744fqq.jpeg" width="800"></li>
</ul>
<p><a href="http://localhost:4000/2019/04/01/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%92%8C%E8%AE%BE%E8%AE%A1%E7%90%86%E5%BF%B5/" title="pulsar系统架构和设计理念" target="_blank" rel="noopener">pulsar系统架构和设计理念</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-centos7同步时间" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/03/19/centos7同步时间/" class="article-date">
      <time datetime="2019-03-19T03:47:39.000Z" itemprop="datePublished">2019-03-19</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/19/centos7同步时间/">centos7同步时间</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="centos7在线同步时间"><a href="#centos7在线同步时间" class="headerlink" title="centos7在线同步时间"></a>centos7在线同步时间</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install ntp //安装ntp服务</span><br><span class="line">systemctl enable ntpd //开机启动服务</span><br><span class="line">systemctl start ntpd //启动服务</span><br><span class="line">timedatectl set-timezone Asia/Shanghai //更改时区</span><br><span class="line">timedatectl set-ntp yes //启用ntp同步</span><br><span class="line">ntpq -p //同步时间</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-安装logstash" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/03/19/安装logstash/" class="article-date">
      <time datetime="2019-03-19T02:23:29.000Z" itemprop="datePublished">2019-03-19</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/19/安装logstash/">安装logstash</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a href="https://www.elastic.co/downloads/logstash" target="_blank" rel="noopener">下载地址</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">wget https://artifacts.elastic.co/downloads/logstash/logstash-6.5.1.tar.gz</span><br><span class="line">tar -zxvf logstash-6.5.1.tar.gz</span><br><span class="line">bin/logstash -e &apos;input&#123;stdin&#123;&#125;&#125;output&#123;stdout&#123;codec=&gt;rubydebug&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<h3 id="像下面这样，说明启动成功了"><a href="#像下面这样，说明启动成功了" class="headerlink" title="像下面这样，说明启动成功了"></a>像下面这样，说明启动成功了</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Pipeline started successfully &#123;:pipeline_id=&gt;&quot;main&quot;, :thread=&gt;&quot;#&lt;Thread:0x678a194a run&gt;&quot;&#125;</span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;</span><br><span class="line">Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br></pre></td></tr></table></figure>
<h3 id="启动成功后在控制台输入-hello-world"><a href="#启动成功后在控制台输入-hello-world" class="headerlink" title="启动成功后在控制台输入 hello, world!"></a>启动成功后在控制台输入 hello, world!</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hello, wrold!</span><br><span class="line">&#123;</span><br><span class="line">    &quot;@timestamp&quot; =&gt; 2018-11-24T15:45:10.941Z,</span><br><span class="line">          &quot;host&quot; =&gt; &quot;localhost.localdomain&quot;,</span><br><span class="line">       &quot;message&quot; =&gt; &quot;hello, wrold!&quot;,</span><br><span class="line">      &quot;@version&quot; =&gt; &quot;1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>小技巧<br>使用 -t 测试配置文件是否有错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./bin/logstash -t -f ./conf.d/test.conf </span><br><span class="line">#如果没有错误应该是这样的</span><br><span class="line">Sending Logstash logs to /usr/local/logstash/logs which is now configured via log4j2.properties</span><br><span class="line">[2018-11-26T09:54:53,868][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified</span><br><span class="line">Configuration OK</span><br><span class="line">[2018-11-26T09:54:58,014][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h3 id="调试脚本"><a href="#调试脚本" class="headerlink" title="调试脚本"></a>调试脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#vi logstash.conf </span><br><span class="line">input &#123;   </span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; [&quot;10.5.74.18:9092&quot;] # 注意这里配置的kafka的broker地址不是zk的地址</span><br><span class="line">        group_id =&gt; &quot;logstash&quot; # 自定义groupid </span><br><span class="line">        topics =&gt; [&quot;log-testi&quot;]  # kafka topic 名称 </span><br><span class="line">        consumer_threads =&gt; 5 </span><br><span class="line">        decorate_events =&gt; true</span><br><span class="line">        codec =&gt; &quot;json&quot;</span><br><span class="line">        type =&gt; &quot;log-test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IPORHOST:remote_ip&#125; - %&#123;DATA:user_name&#125; \[%&#123;HTTPDATE:access_time&#125;\] \&quot;%&#123;WORD:http_method&#125; %&#123;DATA:request_url&#125; HTTP/%&#123;NUMBER:http_version&#125;\&quot; %&#123;NUMBER:response_code&#125; %&#123;NUMBER:body_sent_bytes&#125; \&quot;%&#123;DATA:referrer&#125;\&quot; \&quot;%&#123;DATA:user_agent&#125;\&quot; \&quot;%&#123;DATA:forwarded_for&#125;\&quot;&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">    if [type] == &quot;log-test&quot; &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;10.5.74.18:9200&quot;]</span><br><span class="line">            index =&gt; &quot;%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot; # 最好使用日期，一天一个索引，这样方便删除旧索引</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">#bin/logstash -f logstash.conf</span><br></pre></td></tr></table></figure>
<blockquote>
<p>grok调式工具<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://grokdebug.herokuapp.com/</span><br></pre></td></tr></table></figure></p>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-搭建简单的ELK" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/03/15/搭建简单的ELK/" class="article-date">
      <time datetime="2019-03-15T03:11:28.000Z" itemprop="datePublished">2019-03-15</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/15/搭建简单的ELK/">搭建简单的ELK</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="建立目录"><a href="#建立目录" class="headerlink" title="建立目录"></a>建立目录</h3><pre><code>mkdir -p /opt/elk/nginx/{conf,conf.d,html,logs}
mkdir -p /opt/elk/{elasticsearch,logstash}
</code></pre><h3 id="在-opt-server-elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下："><a href="#在-opt-server-elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下：" class="headerlink" title="在/opt/server/elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下："></a>在/opt/server/elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下：</h3><pre><code>[root@tccp ~]# cd /opt/server/elk/
[root@tccp elk]# tree ./
./
├── docker-compose.yml
├── elasticsearch
│   └── elasticsearch.yml
├── kibana
└── logstash
    └── conf.d
        ├── logstash.conf
</code></pre><h3 id="elasticsearch-yml文件内容如下："><a href="#elasticsearch-yml文件内容如下：" class="headerlink" title="elasticsearch.yml文件内容如下："></a>elasticsearch.yml文件内容如下：</h3><pre><code>cluster.name: &quot;docker-cluster&quot;
network.host: 0.0.0.0discovery.zen.minimum_master_nodes: 1
discovery.type: single-node
</code></pre><h3 id="logstash-conf文件内容如下："><a href="#logstash-conf文件内容如下：" class="headerlink" title="logstash.conf文件内容如下："></a>logstash.conf文件内容如下：</h3><p>`<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line"></span><br><span class="line">       file &#123;</span><br><span class="line"></span><br><span class="line">               start_position =&gt; &quot;beginning&quot;</span><br><span class="line">               path =&gt; [&quot;/var/log/nginx/access.log&quot;]</span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"># 以上file段配置是针对logstash作为agent端收集日志的场景使用，从本地文件输入#下面的注释内容可以忽略，是采用redis作为缓存服务架构方式，这里用不到#        redis &#123;#        host =&gt; &quot;192.168.2.142&quot;#         port =&gt; &quot;6379&quot;#         key =&gt; &quot;filebeat&quot;    #这里的key要与filebeat.yml中定义的key相同#         data_type =&gt; &quot;list&quot;#         threads =&gt; &quot;5&quot;#         db =&gt; &quot;0&quot;#    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line"></span><br><span class="line">        date &#123;</span><br><span class="line">        match =&gt; [ &quot;timestamp&quot;,&quot;dd/MMM/YYYY:H:m:s Z&quot; ]</span><br><span class="line">        remove_field =&gt; &quot;timestamp&quot;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">                elasticsearch &#123;       #输出到elasticsearch服务器，先输出到本地终端查看，没有问题后输出到elasticsearch</span><br><span class="line">                    hosts =&gt; &quot;elasticsearch:9200&quot;  #这里使用elasticsearch容器名称的方式连接到ES</span><br><span class="line">                    index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">                    document_type =&gt; &quot;nginx_logs&quot;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">#               stdout &#123;            #输出到屏幕测试#                    codec =&gt; rubydebug#                &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure></p>
<p>`</p>
<h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line"></span><br><span class="line"> elasticsearch:</span><br><span class="line">    image: elasticsearch</span><br><span class="line">    container_name: elasticsearch</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9200:9200&quot;</span><br><span class="line">      - &quot;9300:9300&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - ./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro</span><br><span class="line">    environment:</span><br><span class="line">       ES_JAVA_OPTS: &quot;-Xmx256m -Xms256m&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line"> logstash:</span><br><span class="line">    image: logstash</span><br><span class="line">    container_name: logstash</span><br><span class="line">    command: logstash -f /etc/logstash/conf.d/logstash.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./logstash/conf.d:/etc/logstash/conf.d</span><br><span class="line">      - ./nginx/logs:/var/log/nginx</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5000:5000&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line"> kibana:</span><br><span class="line">    image: kibana</span><br><span class="line">    restart: &quot;always&quot;</span><br><span class="line">    container_name: kibana</span><br><span class="line">    environment:</span><br><span class="line">      - ELASTICSEARCH_URL=http://elasticsearch:9200</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5601:5601&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line"> nginx:</span><br><span class="line">     image: nginx</span><br><span class="line">     restart: &quot;always&quot;</span><br><span class="line">     container_name: nginx</span><br><span class="line">     ports:</span><br><span class="line">       - &quot;80:80&quot;</span><br><span class="line">     volumes:</span><br><span class="line">        - ./nginx/html:/usr/share/nginx/html</span><br><span class="line">        - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf</span><br><span class="line">        - ./nginx/conf.d:/etc/nginx/conf.d</span><br><span class="line">        - ./nginx/logs:/var/log/nginx</span><br><span class="line">networks:</span><br><span class="line"> elk:</span><br><span class="line">  driver: bridge</span><br></pre></td></tr></table></figure>
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-从零开始搭建一套日志收集分析系统" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/03/14/从零开始搭建一套日志收集分析系统/" class="article-date">
      <time datetime="2019-03-14T08:53:04.000Z" itemprop="datePublished">2019-03-14</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/14/从零开始搭建一套日志收集分析系统/">从零开始搭建一套日志收集分析系统</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h2 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h2><p><img src="/2019/03/14/从零开始搭建一套日志收集分析系统/ELK-Stack.svg" alt></p>
<h2 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h2><h3 id="logrus-kafka-hook-设置"><a href="#logrus-kafka-hook-设置" class="headerlink" title="logrus kafka hook 设置"></a>logrus kafka hook 设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">    &quot;os&quot;</span><br><span class="line">    &quot;log&quot;</span><br><span class="line">    &quot;time&quot;</span><br><span class="line">    &quot;strings&quot;</span><br><span class="line">    &quot;math/rand&quot;</span><br><span class="line">    &quot;crypto/tls&quot;</span><br><span class="line"></span><br><span class="line">    &quot;github.com/sirupsen/logrus&quot;</span><br><span class="line">    &quot;github.com/Shopify/sarama&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type KafkaHook struct &#123;</span><br><span class="line">    Topic       string</span><br><span class="line">    AddHostname bool</span><br><span class="line">    Hostname    string</span><br><span class="line">    levels      []logrus.Level</span><br><span class="line">    Formatter   logrus.Formatter</span><br><span class="line">    Producer    sarama.AsyncProducer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func NewKafakaHook(levels []logrus.Level, formatter logrus.Formatter, topic string, brokers string, addHostname bool, tls *tls.Config) (*KafkaHook, error) &#123;</span><br><span class="line">    var (</span><br><span class="line">        err error</span><br><span class="line">        producer sarama.AsyncProducer</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    config := sarama.NewConfig()</span><br><span class="line">    config.Producer.RequiredAcks = sarama.WaitForLocal</span><br><span class="line">    // config.Producer.Compression = sarama.CompressionSnappy</span><br><span class="line">    config.Producer.Flush.Frequency = 500 * time.Millisecond</span><br><span class="line">    config.Producer.Timeout = 5 * time.Second</span><br><span class="line"></span><br><span class="line">    if tls != nil &#123;</span><br><span class="line">        config.Net.TLS.Enable = true</span><br><span class="line">        config.Net.TLS.Config = tls</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    producer, err = sarama.NewAsyncProducer(strings.Split(brokers, &quot;,&quot;), config)</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">        return nil, err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    go func() &#123;</span><br><span class="line">        errs := producer.Errors()</span><br><span class="line">        for &#123;</span><br><span class="line">            select &#123;</span><br><span class="line">            case err := &lt;-errs:</span><br><span class="line">                if err != nil &#123;</span><br><span class="line">                    log.Printf(&quot;Failed to send log entry to Kafka: %v\n&quot;, err)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    hostname, err := os.Hostname()</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">        hostname = &quot;localhost&quot;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    hook := &amp;KafkaHook&#123;</span><br><span class="line">        topic,</span><br><span class="line">        addHostname,</span><br><span class="line">        hostname,</span><br><span class="line">        levels,</span><br><span class="line">        formatter,</span><br><span class="line">        producer,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return hook, nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (kh *KafkaHook) Fire(entry *logrus.Entry) error &#123;</span><br><span class="line">    var (</span><br><span class="line">        bt []byte</span><br><span class="line">        err error</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    if bt, err = entry.Time.MarshalBinary(); err != nil &#123;</span><br><span class="line">        return err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if kh.AddHostname &#123;</span><br><span class="line">        if _, ok := entry.Data[&quot;host&quot;]; !ok &#123;</span><br><span class="line">            entry.Data[&quot;host&quot;] = kh.Hostname</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if bt, err = kh.Formatter.Format(entry); err != nil &#123;</span><br><span class="line">        return err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    value := sarama.ByteEncoder(bt)</span><br><span class="line"></span><br><span class="line">    kh.Producer.Input() &lt;- &amp;sarama.ProducerMessage&#123;</span><br><span class="line">        Topic: kh.Topic,</span><br><span class="line">        Value: value,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (kh *KafkaHook) Levels() []logrus.Level &#123;</span><br><span class="line">    return kh.levels</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">   hook, err := NewKafakaHook(</span><br><span class="line">      []logrus.Level&#123;</span><br><span class="line">         logrus.DebugLevel,</span><br><span class="line">         logrus.InfoLevel,</span><br><span class="line">         logrus.ErrorLevel,</span><br><span class="line">         logrus.WarnLevel,</span><br><span class="line">      &#125;,</span><br><span class="line">      &amp;logrus.JSONFormatter&#123;&#125;,</span><br><span class="line">      &quot;log-dev&quot;,</span><br><span class="line">      &quot;10.9.X.A:9092,10.9.X.B:9092,10.9.X.C:9092&quot;,</span><br><span class="line">      true,</span><br><span class="line">      nil,</span><br><span class="line">   )</span><br><span class="line">   if err != nil &#123;</span><br><span class="line">      log.Println(err)</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   logger := logrus.New()</span><br><span class="line">   logger.SetLevel(logrus.DebugLevel)</span><br><span class="line">   logger.Hooks.Add(hook)</span><br><span class="line"></span><br><span class="line">   n := 0</span><br><span class="line">   for &#123;</span><br><span class="line">      n++</span><br><span class="line">      r := rand.Intn(1&lt;&lt;10)</span><br><span class="line">      time.Sleep(time.Millisecond * time.Duration(r))</span><br><span class="line">      switch &#123;</span><br><span class="line">      case r &lt; 512: logger.Info(&quot;this is an info message &quot; + strconv.Itoa(n))</span><br><span class="line">      case r &gt;= 512 &amp;&amp; r &lt; 869: logger.Warn(&quot;this is a warn message &quot; + strconv.Itoa(n))</span><br><span class="line">      case r &gt;= 869 &amp;&amp; r &lt; 985: logger.Debug(&quot;this is a debug message &quot; + strconv.Itoa(n))</span><br><span class="line">      case r &gt;= 985: logger.Error(&quot;this is an error message &quot; + strconv.Itoa(n))</span><br><span class="line">      default:</span><br><span class="line">         logger.Warn(&quot;unexpected message&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h3><h5 id="在需要抓取日志的机器上安装并配置-Filebeat"><a href="#在需要抓取日志的机器上安装并配置-Filebeat" class="headerlink" title="在需要抓取日志的机器上安装并配置 Filebeat"></a>在需要抓取日志的机器上安装并配置 Filebeat</h5><p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html</a><br>以 ubuntu:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-amd64.deb</span><br><span class="line">sudo dpkg -i filebeat-6.3.2-amd64.deb</span><br></pre></td></tr></table></figure></p>
<p>centos:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpm</span><br><span class="line">sudo rpm -vi filebeat-6.3.2-x86_64.rpm</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>最好使用 6.3 版本，我试过升级到 6.4 结果原先的配置会出问题</p>
</blockquote>
<h5 id="启动和停止"><a href="#启动和停止" class="headerlink" title="启动和停止"></a>启动和停止</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start filebeat   # sudo /etc/init.d/filebeat start</span><br><span class="line">systemctl restart filebeat    # sudo /etc/init.d/filebeat restart</span><br><span class="line">systemctl stop filebeat   # sudo /etc/init.d/filebeat stop</span><br></pre></td></tr></table></figure>
<h5 id="默认路径"><a href="#默认路径" class="headerlink" title="默认路径:"></a>默认路径:</h5><ul>
<li>home: /usr/share/filebeat</li>
<li>bin: /usr/share/filebeat/bin</li>
<li>config: /etc/filebeat</li>
<li>data: /var/lib/filebeat</li>
<li>logs: /var/log/filebeat</li>
</ul>
<h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>编辑 filebeat.yml 文件添加输入、输出等配置，比如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">## vi /etc/filebeat/filebeat.yml</span><br><span class="line"></span><br><span class="line">## Log Input 相关属性设置: https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html</span><br><span class="line">filebeat.inputs:</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/req/req-worker-*.log # 文件名和目录名都可以用通配符，不过 path/*/*.log 不包括 path 根目录的文件</span><br><span class="line">    fields: # 添加额外的字段</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-req&quot;</span><br><span class="line">    fields_under_root: true # field 字段会放在根索引下，否则会放在 fields 字段下</span><br><span class="line">    ignore_older: 24h # 忽略 24 小时前的文件</span><br><span class="line">    scan_frequency: 11s # 设置不同的时间，这样可以错开扫描高峰</span><br><span class="line">    max_backoff: 11s</span><br><span class="line">    backoff: 11s</span><br><span class="line">    harvester_buffer_size: 51200 # 采集的 buffer 大小</span><br><span class="line">    close_timeout: 1h # 因为我这里的文件是一个小时产生一个，所以直接设置采集器默认 1 小时关闭</span><br><span class="line">    clean_inactive: 25h # 需要大于 ignore_older + scan_frequency，有效地清理可以减小 registry 文件的大小和当中记录的文件条目数量</span><br><span class="line">    harvester_limit: 10 # 限制最多爬取个数，默认不限制，如果碰到文件数很多一开始会占用大量 cpu</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/push/push-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-push&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 19s</span><br><span class="line">    max_backoff: 19s</span><br><span class="line">    backoff: 19s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/send/send-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-send&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 13s</span><br><span class="line">    max_backoff: 13s</span><br><span class="line">    backoff: 13s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/sync/sync-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-sync&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 17s</span><br><span class="line">    max_backoff: 17s</span><br><span class="line">    backoff: 17s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/delete/delete-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-delete&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 71s</span><br><span class="line">    max_backoff: 71s</span><br><span class="line">    backoff: 71s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">        - /var/log/php/error.log</span><br><span class="line">    fields:</span><br><span class="line">        log_topic: &quot;log-im&quot;</span><br><span class="line">        service: &quot;backend-php-error&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 23s</span><br><span class="line">    max_backoff: 23s</span><br><span class="line">    backoff: 23s</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    close_renamed: true # 因为这个日志文件会定期重命名并压缩，所以设置 close_renamed 可以关闭采集器</span><br><span class="line">    multiline.pattern: &apos;^\[[0-9]&#123;2&#125;-[A-Z]&#123;1&#125;[a-z]&#123;2&#125;-[0-9]&#123;4&#125;&apos; # 合并多行日志，将类似 [06-Sep-2018 ... 开头的日志向后合并</span><br><span class="line">    multiline.negate: true</span><br><span class="line">    multiline.match: after</span><br><span class="line">    harvester_limit: 10</span><br><span class="line"></span><br><span class="line">## Kafka Output 相关属性设置: https://www.elastic.co/guide/en/beats/filebeat/current/kafka-output.html</span><br><span class="line">output.kafka:</span><br><span class="line">  enabled: true</span><br><span class="line">  hosts: [&quot;10.10.X.A:9092&quot;, &quot;10.10.X.B:9092&quot;, &quot;10.10.X.C:9092&quot;]</span><br><span class="line">  topic: &apos;%&#123;[log_topic]&#125;&apos;</span><br><span class="line">  codec.format:</span><br><span class="line">    string: &apos;%&#123;[beat][hostname]&#125; %&#123;[service]&#125; %&#123;[message]&#125;&apos; # 传给 logstash 时可以用 grok 过滤插件设置 `match =&gt; &#123; &quot;message&quot; =&gt; &quot;^%&#123;DATA:hostname&#125; %&#123;DATA:service&#125; (?&lt;message&gt;.*)&quot;&#125;` 解析</span><br><span class="line">    # 如果设成 ‘%&#123;[message]&#125;’，则是原样转发消息</span><br><span class="line">  partition.round_robin:</span><br><span class="line">    reachable_only: false</span><br><span class="line">  required_acks: 1</span><br><span class="line">  compression: none # 默认是 gzip，如果像节省开销可以设成 none</span><br><span class="line">  bulk_max_size: 100</span><br><span class="line">  max_message_bytes: 1000000 # 不要超过 kafka server 端设置的 message.max.size，否则超过的部分会被丢弃</span><br><span class="line"></span><br><span class="line">output.file:</span><br><span class="line">  enabled: false</span><br><span class="line">  path: /home/ubuntu/test-log</span><br><span class="line">  filename: output.log</span><br><span class="line">  permissions: 0644</span><br><span class="line">  codec.format:</span><br><span class="line">    string: &apos;%&#123;[message]&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<p><a href="https://cloud.tencent.com/developer/article/1006051" title="Filebeat 配置详解" target="_blank" rel="noopener">Filebeat 配置详解</a><br>假设 Filebeat 要抓取的是非结构化日志格式:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Mon Sep 10 2018 12:06:16 GMT+0800 (CST) - info: type: SyncSessionRangeService  uid:9182093812301298392103&#123;&#125;</span><br><span class="line"></span><br><span class="line">18-09-07 08:19:43 - info: GRPC REQUEST &amp; RESPONSE&#123;</span><br><span class="line">        &quot;uid&quot;: 1290381298494,</span><br><span class="line">        &quot;type&quot;: &quot;SyncSessionRangeService&quot;,</span><br><span class="line">        &quot;data&quot;: &#123;</span><br><span class="line">            &quot;session_id&quot;: 123456,</span><br><span class="line">            &quot;session_type&quot;: 2,</span><br><span class="line">            &quot;start_id&quot;: 0,</span><br><span class="line">            &quot;stop_id&quot;: 3</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;localId&quot;: 349058034598,</span><br><span class="line">        &quot;result&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: 5,</span><br><span class="line">            &quot;is_sync&quot;: true,</span><br><span class="line">            &quot;is_ack&quot;: true,</span><br><span class="line">            &quot;require_ack&quot;: false,</span><br><span class="line">            &quot;error&quot;: 0,</span><br><span class="line">            &quot;continue&quot;: false,</span><br><span class="line">            &quot;sync_local_id&quot;: 0,</span><br><span class="line">            &quot;messages&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">18-09-06 22:07:33 - info: type: SyncSessionRangeService  uid:20373933&#123;&#125;</span><br><span class="line"></span><br><span class="line">18-09-07 08:19:43 - info: GRPC REQUEST &amp; RESPONSE&#123;</span><br><span class="line">            &quot;uid&quot;: 5792715,</span><br><span class="line">            &quot;type&quot;: &quot;SyncSessionRangeService&quot;,</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;session_id&quot;: 13416794,</span><br><span class="line">                &quot;session_type&quot;: 2,</span><br><span class="line">                &quot;start_id&quot;: 0,</span><br><span class="line">                &quot;stop_id&quot;: 3</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;localId&quot;: 1536279501,</span><br><span class="line">            &quot;result&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: 5,</span><br><span class="line">                &quot;is_sync&quot;: true,</span><br><span class="line">                &quot;is_ack&quot;: true,</span><br><span class="line">                &quot;require_ack&quot;: false,</span><br><span class="line">                &quot;error&quot;: 0,</span><br><span class="line">                &quot;continue&quot;: false,</span><br><span class="line">                &quot;sync_local_id&quot;: 0,</span><br><span class="line">                &quot;messages&quot;: []</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">[08/Sep/2018:01:49:55 +0800] check photo https://sgchatfiles.bldimg.com/2018/9/8/1/49/16263641_1536342594629.jpg</span><br><span class="line"></span><br><span class="line">[08/Sep/2018:01:49:55 +0800] check &quot;result&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: 5,</span><br><span class="line">    &quot;is_sync&quot;: true,</span><br><span class="line">    &quot;is_ack&quot;: true,</span><br><span class="line">    &quot;require_ack&quot;: false,</span><br><span class="line">    &quot;error&quot;: 0,</span><br><span class="line">    &quot;continue&quot;: false,</span><br><span class="line">    &quot;sync_local_id&quot;: 0,</span><br><span class="line">    &quot;messages&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>对于多行日志，使用 multiline.pattern 处理:<a href="https://www.elastic.co/guide/en/beats/filebeat/current/multiline-examples.html" target="_blank" rel="noopener">参考</a></p>
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p><a href="https://262986832.github.io/2019/03/14/%E5%AE%89%E8%A3%85kafka/" target="_blank" rel="noopener">安装过程</a></p>
<h3 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h3><p>ELK 主要是以 docker-elk 为模板进行搭建，选择的版本是 6.3<br>不过该项目是搭建在单节点上的配置，如果是用在生产环境的多主机上要修改很多地方，这是我修改的 docker-elk<br>创建文件目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/elk/elasticsearch/config</span><br><span class="line">mkdir -p /opt/elk/elasticsearch/data</span><br><span class="line">mkdir -p /opt/elk/extensions/curator/curator</span><br><span class="line">mkdir -p /opt/elk/extensions/logspout</span><br><span class="line">mkdir -p /opt/elk/kibana/config</span><br><span class="line">mkdir -p /opt/elk/logstash/config</span><br><span class="line">mkdir -p /opt/elk/logstash/pipeline</span><br><span class="line">$ tree .</span><br><span class="line">.</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">├── elasticsearch</span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── elasticsearch.yml</span><br><span class="line">│   └──data</span><br><span class="line">├── extensions</span><br><span class="line">│   ├── curator</span><br><span class="line">│   │   ├── config</span><br><span class="line">│   │   │   ├── curator.yml</span><br><span class="line">│   │   │   └── delete_log_files_curator.yml</span><br><span class="line">│   │   ├── curator-compose.yml</span><br><span class="line">│   │   ├── </span><br><span class="line">│   │   ├── entrypoint.sh</span><br><span class="line">│   │   └── README.md</span><br><span class="line">│   ├── logspout</span><br><span class="line">│   │   ├── build.sh</span><br><span class="line">│   │   ├── Dockerfile</span><br><span class="line">│   │   ├── logspout-compose.yml</span><br><span class="line">│   │   ├── modules.go</span><br><span class="line">│   │   └── README.md</span><br><span class="line">│   └── README.md</span><br><span class="line">├── kibana</span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── kibana.yml</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── LICENSE</span><br><span class="line">├── logstash</span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── logstash.yml</span><br><span class="line">│   ├── Dockerfile</span><br><span class="line">│   └── pipeline</span><br><span class="line">│       └── logstash.conf</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure></p>
<p><em>docker-compose.yml</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">#vi docker-compose.yml </span><br><span class="line">version: &apos;2.2&apos; # version 2.2 以上加 docker-compose 1.16+ 才支持 cpus 的设置项</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  elasticsearch:</span><br><span class="line">    image: elasticsearch</span><br><span class="line">    container_name: elasticsearch</span><br><span class="line">    volumes:</span><br><span class="line">      - ./elasticsearch/data:/usr/share/elasticsearch/data # 设置 es 数据存放目录</span><br><span class="line">      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9200:9200&quot;</span><br><span class="line">      - &quot;9300:9300&quot;</span><br><span class="line">    cpus: 1.5 # 限制 cpu 的使用，两核的处理器设置 1.5 代表最多占用 1.5/2 (75%) 的 cpu</span><br><span class="line">    mem_limit: 6g # 限制容器最多占用 6g 内存</span><br><span class="line">    ulimits: # 必须设置此项 bootstrap.memory_lock 才能生效</span><br><span class="line">      memlock:</span><br><span class="line">        soft: -1</span><br><span class="line">        hard: -1</span><br><span class="line">    environment:</span><br><span class="line">      ES_JAVA_OPTS: &quot;-Xmx3g -Xms3g&quot; # 设置 Java 堆内存大小，最好设置成主机的一半但也不能超过 32g</span><br><span class="line">      PUBLISH_HOST: &quot;10.5.74.18&quot; # host ip</span><br><span class="line">      NODE_NAME: &quot;es-node-1&quot; # 新的节点，需要修改</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">      </span><br><span class="line">  kibana:</span><br><span class="line">    image: kibana</span><br><span class="line">    container_name: kibana</span><br><span class="line">    volumes:</span><br><span class="line">      - ./kibana/config/:/usr/share/kibana/config:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5601:5601&quot;</span><br><span class="line">    environment:</span><br><span class="line">      - ELASTICSEARCH_URL=http://10.5.74.18:9200</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line">      </span><br><span class="line">  logstash:</span><br><span class="line">    image: logstash</span><br><span class="line">    container_name: logstash</span><br><span class="line">    volumes:</span><br><span class="line">      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro</span><br><span class="line">      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5000:5000&quot;</span><br><span class="line">    cpus: 1.5</span><br><span class="line">    mem_limit: 1g</span><br><span class="line">    environment:</span><br><span class="line">      LS_JAVA_OPTS: &quot;-Xmx512m -Xms512m&quot;</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line"></span><br><span class="line">  cerebro:</span><br><span class="line">    image: yannart/cerebro</span><br><span class="line">    container_name: cerebro</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9000:9000&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line">networks:</span><br><span class="line"> elk:</span><br><span class="line">  driver: bridge</span><br></pre></td></tr></table></figure></p>
<h3 id="logstash-配置"><a href="#logstash-配置" class="headerlink" title="logstash 配置"></a>logstash 配置</h3><p>这里只是作为同一个 group 里的消费者，按一定方式分摊消费 kafka 队列中的消息<br><em>logstash.conf</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">#vi logstash/pipeline/logstash.conf </span><br><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;10.5.74.18:9092,10.5.74.18:9092,10.5.74.18:9092&quot;</span><br><span class="line">        consumer_threads =&gt; 3 # 一般设为 Partition 的数目即可</span><br><span class="line">        decorate_events =&gt; false</span><br><span class="line">        topics =&gt; [&quot;log-im&quot;]</span><br><span class="line">        group_id =&gt; &quot;group-log-im&quot;</span><br><span class="line">        type =&gt; &quot;log-im&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;10.5.74.18:9092,10.5.74.18:9092,10.5.74.18:9092&quot;</span><br><span class="line">        consumer_threads =&gt; 3</span><br><span class="line">        decorate_events =&gt; false</span><br><span class="line">        topics =&gt; [&quot;log-dev&quot;]</span><br><span class="line">        group_id =&gt; &quot;group-log-dev&quot;</span><br><span class="line">        type =&gt; &quot;log-dev&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">## Add your filters / logstash plugins configuration here</span><br><span class="line">filter &#123;</span><br><span class="line">    mutate &#123;</span><br><span class="line">        remove_field =&gt; [ &quot;@version&quot; ]</span><br><span class="line">    &#125;</span><br><span class="line">    if [type] == &quot;log-im&quot; &#123;</span><br><span class="line">        # grok 插件可以将非结构化日志解析成结构化的</span><br><span class="line">        # 测试工具: http://grokdebug.herokuapp.com</span><br><span class="line">        # 推荐阅读: https://www.elastic.co/blog/do-you-grok-grok</span><br><span class="line">        grok &#123;</span><br><span class="line">            match =&gt; &#123; &quot;message&quot; =&gt; &quot;^%&#123;DATA:hostname&#125; %&#123;DATA:service&#125; (?&lt;message&gt;.*)&quot; &#125;</span><br><span class="line">            overwrite =&gt; [ &quot;message&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        grok &#123;</span><br><span class="line">            match =&gt; &#123;</span><br><span class="line">                &quot;message&quot; =&gt; [</span><br><span class="line">                    &quot;^\[%&#123;DATA:time&#125;\] (?&lt;message&gt;.*)&quot;,</span><br><span class="line">                    &quot;^(?&lt;time&gt;[T|M|W|S|F]&#123;1&#125;[a-z]&#123;2&#125; [J|F|M|A|S|O|N|D]&#123;1&#125;[a-z]&#123;2&#125; [0-9]&#123;2&#125; [0-9]&#123;4&#125; [0-9]&#123;2&#125;:[0-9]&#123;2&#125;:[0-9]&#123;2&#125; [GMT+]&#123;4&#125;[0-9]&#123;4&#125; [(CST)]&#123;5&#125;) - %&#123;LOGLEVEL:level&#125;: (?&lt;message&gt;.*)&quot;,</span><br><span class="line">                    &quot;^(?&lt;time&gt;[0-9]&#123;2&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125; [0-9]&#123;2&#125;:[0-9]&#123;2&#125;:[0-9]&#123;2&#125;) - %&#123;LOGLEVEL:level&#125;: (?&lt;message&gt;.*)&quot;,</span><br><span class="line">                    &quot;^(?&lt;message&gt;.*)&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">            overwrite =&gt; [ &quot;message&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        json &#123;</span><br><span class="line">            source =&gt; &quot;message&quot;</span><br><span class="line">            skip_on_invalid_json =&gt; true</span><br><span class="line">            remove_field =&gt; [ &quot;message&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        date &#123;</span><br><span class="line">            match =&gt; [ &quot;time&quot;, &quot;ISO8601&quot;, &quot;EEE MMM dd yyyy HH:mm:ss &apos;GMT&apos;Z &apos;(CST)&apos;&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot;, &quot;yy-MM-dd HH:mm:ss&quot;, &quot;dd-MMM-yyyy HH:mm:ss ZZZ&quot;, &quot;yyyy-MM-dd HH:mm:ss ZZ&quot;, &quot;yyyy-MM-dd HH:mm ZZ&quot; ]</span><br><span class="line">            remove_field =&gt; [ &quot;time&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        if [service] == &quot;backend-php-error&quot; &#123;</span><br><span class="line">            mutate &#123;</span><br><span class="line">                add_field =&gt; &#123; &quot;level&quot; =&gt; &quot;error&quot; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    ## 根据 type 区分不同的 topic 日志，然后存入不同的 index 中，方便 Kibana 聚合</span><br><span class="line">    if [type] == &quot;log-im&quot; &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;10.5.74.18:9200&quot;, &quot;10.42.75.252:9200&quot;, &quot;10.42.111.182:9200&quot;]</span><br><span class="line">            index =&gt; &quot;%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot; # 最好使用日期，一天一个索引，这样方便删除旧索引</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if [type] == &quot;log-dev-2&quot; &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;10.5.74.18:9200&quot;, &quot;10.42.75.252:9200&quot;, &quot;10.42.111.182:9200&quot;]</span><br><span class="line">            index =&gt; &quot;log-dev-2&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><em>logstash.yml:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi logstash/config/logstash.yml</span><br><span class="line">## Default Logstash configuration from logstash-docker.</span><br><span class="line">## from https://github.com/elastic/logstash-docker/blob/master/build/logstash/config/logstash-oss.yml</span><br><span class="line">http.host: &quot;0.0.0.0&quot;</span><br><span class="line">path.config: /usr/share/logstash/pipeline</span><br><span class="line"></span><br><span class="line">pipeline.workers: 4 # 设置成 cpu 核数或者其倍数</span><br><span class="line">pipeline.output.workers: 4</span><br><span class="line">pipeline.batch.size: 1000</span><br><span class="line">pipeline.batch.delay: 10</span><br></pre></td></tr></table></figure></p>
<h3 id="ES-的集群设置"><a href="#ES-的集群设置" class="headerlink" title="ES 的集群设置"></a>ES 的集群设置</h3><p>ES 节点有很多种角色，比如常见的 master、data、injest 节点，我这里是将三个节点作为 master 和 injest，另外三个作为 data 节点。<br><em>elasticsearch.yml:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">## vi elasticsearch/config/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">## Default Elasticsearch configuration from elasticsearch-docker.</span><br><span class="line">## from https://github.com/elastic/elasticsearch-docker/blob/master/build/elasticsearch/elasticsearch.yml</span><br><span class="line">cluster.name: &quot;elk-cluster&quot;</span><br><span class="line"></span><br><span class="line">node.name: $&#123;NODE_NAME&#125;</span><br><span class="line">node.master: true</span><br><span class="line"></span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">network.publish_host: $&#123;PUBLISH_HOST&#125;</span><br><span class="line"></span><br><span class="line">## https://www.elastic.co/guide/en/elasticsearch/reference/6.3/setup-configuration-memory.html</span><br><span class="line">## 最好按照官方说的关闭内存交换并设置此项为 true，容器的话需要设置 ulimit</span><br><span class="line">bootstrap.memory_lock: true</span><br><span class="line"></span><br><span class="line">## 集群单播 ip</span><br><span class="line">discovery.zen.ping.unicast.hosts: [&quot;10.5.74.18:9300&quot;, &quot;10.5.74.19:9300&quot;, &quot;10.5.74.20:9300&quot;]</span><br><span class="line">discovery.zen.fd.ping_timeout: 120s</span><br><span class="line">discovery.zen.fd.ping_retries: 6</span><br><span class="line">discovery.zen.fd.ping_interval: 30s</span><br><span class="line"></span><br><span class="line">## 设置此项，当 fielddata 达到预设值时会清除旧数据，有利于新数据的写入</span><br><span class="line">indices.fielddata.cache.size: 30%</span><br><span class="line"></span><br><span class="line">## 避免集群整个重启时频繁交换分片的问题</span><br><span class="line">gateway.recover_after_nodes: 2</span><br><span class="line">gateway.expected_nodes: 3</span><br><span class="line">gateway.recover_after_time: 5m</span><br><span class="line"></span><br><span class="line"># 防止脑裂，推荐设成: 候选主节点数除二加一</span><br><span class="line"># recommend set: (masters) / 2 + 1</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure></p>
<h3 id="配置Kibana"><a href="#配置Kibana" class="headerlink" title="配置Kibana"></a>配置Kibana</h3><p>默认访问同一主机上的 ES 节点即可<br><em>kibana.yml</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">## vi kibana/config/kibana.yml</span><br><span class="line"></span><br><span class="line">## Default Kibana configuration from kibana-docker.</span><br><span class="line">## from https://github.com/elastic/kibana-docker/blob/master/build/kibana/config/kibana.yml</span><br><span class="line">server.name: kibana</span><br><span class="line">server.host: &quot;0&quot;</span><br><span class="line">elasticsearch.requestTimeout: 90000</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>修改主机配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w vm.max_map_count=262144</span><br><span class="line">echo &quot;vm.max_map_count=262144&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure></p>
</blockquote>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Filebeat/">Filebeat</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/elk/">elk</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-docker-compose安装" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2019/03/14/docker-compose安装/" class="article-date">
      <time datetime="2019-03-14T08:47:48.000Z" itemprop="datePublished">2019-03-14</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/03/14/docker-compose安装/">docker compose安装</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h5 id="安装-Docker-Compose"><a href="#安装-Docker-Compose" class="headerlink" title="安装 Docker-Compose"></a>安装 Docker-Compose</h5><h5 id="下载最新版本的-docker-compose-到-usr-bin-目录下"><a href="#下载最新版本的-docker-compose-到-usr-bin-目录下" class="headerlink" title="下载最新版本的 docker-compose 到 /usr/bin 目录下"></a>下载最新版本的 docker-compose 到 /usr/bin 目录下</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -L https://github.com/docker/compose/releases/download/1.23.2/docker-compose-`uname -s`-`uname -m` -o /usr/bin/docker-compose</span><br></pre></td></tr></table></figure>
<h5 id="给-docker-compose-授权"><a href="#给-docker-compose-授权" class="headerlink" title="给 docker-compose 授权"></a>给 docker-compose 授权</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /usr/bin/docker-compose</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2019 Fvelement
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="快速、简洁且高效的博客框架">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="简而不减 Hexo 双栏博客主题  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style="display:none">
                        <span id="site-visit" title="本站到访数"><i class="fa fa-user" aria-hidden="true"></i><span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style="display:none">
                        <span id="page-visit" title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 6;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
            
            
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>