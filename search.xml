<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>centos7同步时间</title>
      <link href="/2019/03/19/centos7%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4/"/>
      <url>/2019/03/19/centos7%E5%90%8C%E6%AD%A5%E6%97%B6%E9%97%B4/</url>
      
        <content type="html"><![CDATA[<h3 id="centos7在线同步时间"><a href="#centos7在线同步时间" class="headerlink" title="centos7在线同步时间"></a>centos7在线同步时间</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install ntp //安装ntp服务</span><br><span class="line">systemctl enable ntpd //开机启动服务</span><br><span class="line">systemctl start ntpd //启动服务</span><br><span class="line">timedatectl set-timezone Asia/Shanghai //更改时区</span><br><span class="line">timedatectl set-ntp yes //启用ntp同步</span><br><span class="line">ntpq -p //同步时间</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>安装logstash</title>
      <link href="/2019/03/19/%E5%AE%89%E8%A3%85logstash/"/>
      <url>/2019/03/19/%E5%AE%89%E8%A3%85logstash/</url>
      
        <content type="html"><![CDATA[<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p><a href="https://www.elastic.co/downloads/logstash" target="_blank" rel="noopener">下载地址</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">wget https://artifacts.elastic.co/downloads/logstash/logstash-6.5.1.tar.gz</span><br><span class="line">tar -zxvf logstash-6.5.1.tar.gz</span><br><span class="line">bin/logstash -e &apos;input&#123;stdin&#123;&#125;&#125;output&#123;stdout&#123;codec=&gt;rubydebug&#125;&#125;&apos;</span><br></pre></td></tr></table></figure></p><h3 id="像下面这样，说明启动成功了"><a href="#像下面这样，说明启动成功了" class="headerlink" title="像下面这样，说明启动成功了"></a>像下面这样，说明启动成功了</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Pipeline started successfully &#123;:pipeline_id=&gt;&quot;main&quot;, :thread=&gt;&quot;#&lt;Thread:0x678a194a run&gt;&quot;&#125;</span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">Pipelines running &#123;:count=&gt;1, :running_pipelines=&gt;[:main], :non_running_pipelines=&gt;[]&#125;</span><br><span class="line">Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br></pre></td></tr></table></figure><h3 id="启动成功后在控制台输入-hello-world"><a href="#启动成功后在控制台输入-hello-world" class="headerlink" title="启动成功后在控制台输入 hello, world!"></a>启动成功后在控制台输入 hello, world!</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hello, wrold!</span><br><span class="line">&#123;</span><br><span class="line">    &quot;@timestamp&quot; =&gt; 2018-11-24T15:45:10.941Z,</span><br><span class="line">          &quot;host&quot; =&gt; &quot;localhost.localdomain&quot;,</span><br><span class="line">       &quot;message&quot; =&gt; &quot;hello, wrold!&quot;,</span><br><span class="line">      &quot;@version&quot; =&gt; &quot;1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>小技巧<br>使用 -t 测试配置文件是否有错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">./bin/logstash -t -f ./conf.d/test.conf </span><br><span class="line">#如果没有错误应该是这样的</span><br><span class="line">Sending Logstash logs to /usr/local/logstash/logs which is now configured via log4j2.properties</span><br><span class="line">[2018-11-26T09:54:53,868][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified</span><br><span class="line">Configuration OK</span><br><span class="line">[2018-11-26T09:54:58,014][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash</span><br></pre></td></tr></table></figure></p></blockquote><h3 id="调试脚本"><a href="#调试脚本" class="headerlink" title="调试脚本"></a>调试脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">#vi logstash.conf </span><br><span class="line">input &#123;   </span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; [&quot;10.5.74.18:9092&quot;] # 注意这里配置的kafka的broker地址不是zk的地址</span><br><span class="line">        group_id =&gt; &quot;logstash&quot; # 自定义groupid </span><br><span class="line">        topics =&gt; [&quot;log-testi&quot;]  # kafka topic 名称 </span><br><span class="line">        consumer_threads =&gt; 5 </span><br><span class="line">        decorate_events =&gt; true</span><br><span class="line">        codec =&gt; &quot;json&quot;</span><br><span class="line">        type =&gt; &quot;log-test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IPORHOST:remote_ip&#125; - %&#123;DATA:user_name&#125; \[%&#123;HTTPDATE:access_time&#125;\] \&quot;%&#123;WORD:http_method&#125; %&#123;DATA:request_url&#125; HTTP/%&#123;NUMBER:http_version&#125;\&quot; %&#123;NUMBER:response_code&#125; %&#123;NUMBER:body_sent_bytes&#125; \&quot;%&#123;DATA:referrer&#125;\&quot; \&quot;%&#123;DATA:user_agent&#125;\&quot; \&quot;%&#123;DATA:forwarded_for&#125;\&quot;&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">    if [type] == &quot;log-test&quot; &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;10.5.74.18:9200&quot;]</span><br><span class="line">            index =&gt; &quot;%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot; # 最好使用日期，一天一个索引，这样方便删除旧索引</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">#bin/logstash -f logstash.conf</span><br></pre></td></tr></table></figure><blockquote><p>grok调式工具<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://grokdebug.herokuapp.com/</span><br></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>搭建简单的ELK</title>
      <link href="/2019/03/15/%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84ELK/"/>
      <url>/2019/03/15/%E6%90%AD%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84ELK/</url>
      
        <content type="html"><![CDATA[<h3 id="建立目录"><a href="#建立目录" class="headerlink" title="建立目录"></a>建立目录</h3><pre><code>mkdir -p /opt/elk/nginx/{conf,conf.d,html,logs}mkdir -p /opt/elk/{elasticsearch,logstash}</code></pre><h3 id="在-opt-server-elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下："><a href="#在-opt-server-elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下：" class="headerlink" title="在/opt/server/elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下："></a>在/opt/server/elk目录下创建对应容器的目录和其配置文件，用作挂载，整个目录结构如下：</h3><pre><code>[root@tccp ~]# cd /opt/server/elk/[root@tccp elk]# tree ././├── docker-compose.yml├── elasticsearch│   └── elasticsearch.yml├── kibana└── logstash    └── conf.d        ├── logstash.conf</code></pre><h3 id="elasticsearch-yml文件内容如下："><a href="#elasticsearch-yml文件内容如下：" class="headerlink" title="elasticsearch.yml文件内容如下："></a>elasticsearch.yml文件内容如下：</h3><pre><code>cluster.name: &quot;docker-cluster&quot;network.host: 0.0.0.0discovery.zen.minimum_master_nodes: 1discovery.type: single-node</code></pre><h3 id="logstash-conf文件内容如下："><a href="#logstash-conf文件内容如下：" class="headerlink" title="logstash.conf文件内容如下："></a>logstash.conf文件内容如下：</h3><p>`<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line"></span><br><span class="line">       file &#123;</span><br><span class="line"></span><br><span class="line">               start_position =&gt; &quot;beginning&quot;</span><br><span class="line">               path =&gt; [&quot;/var/log/nginx/access.log&quot;]</span><br><span class="line"></span><br><span class="line">       &#125;</span><br><span class="line"># 以上file段配置是针对logstash作为agent端收集日志的场景使用，从本地文件输入#下面的注释内容可以忽略，是采用redis作为缓存服务架构方式，这里用不到#        redis &#123;#        host =&gt; &quot;192.168.2.142&quot;#         port =&gt; &quot;6379&quot;#         key =&gt; &quot;filebeat&quot;    #这里的key要与filebeat.yml中定义的key相同#         data_type =&gt; &quot;list&quot;#         threads =&gt; &quot;5&quot;#         db =&gt; &quot;0&quot;#    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line"></span><br><span class="line">        date &#123;</span><br><span class="line">        match =&gt; [ &quot;timestamp&quot;,&quot;dd/MMM/YYYY:H:m:s Z&quot; ]</span><br><span class="line">        remove_field =&gt; &quot;timestamp&quot;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">                elasticsearch &#123;       #输出到elasticsearch服务器，先输出到本地终端查看，没有问题后输出到elasticsearch</span><br><span class="line">                    hosts =&gt; &quot;elasticsearch:9200&quot;  #这里使用elasticsearch容器名称的方式连接到ES</span><br><span class="line">                    index =&gt; &quot;logstash-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">                    document_type =&gt; &quot;nginx_logs&quot;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">#               stdout &#123;            #输出到屏幕测试#                    codec =&gt; rubydebug#                &#125;</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure></p><p>`</p><h3 id="docker-compose-yml"><a href="#docker-compose-yml" class="headerlink" title="docker-compose.yml"></a>docker-compose.yml</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line"></span><br><span class="line"> elasticsearch:</span><br><span class="line">    image: elasticsearch</span><br><span class="line">    container_name: elasticsearch</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9200:9200&quot;</span><br><span class="line">      - &quot;9300:9300&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - ./elasticsearch/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro</span><br><span class="line">    environment:</span><br><span class="line">       ES_JAVA_OPTS: &quot;-Xmx256m -Xms256m&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line"> logstash:</span><br><span class="line">    image: logstash</span><br><span class="line">    container_name: logstash</span><br><span class="line">    command: logstash -f /etc/logstash/conf.d/logstash.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./logstash/conf.d:/etc/logstash/conf.d</span><br><span class="line">      - ./nginx/logs:/var/log/nginx</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5000:5000&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line"> kibana:</span><br><span class="line">    image: kibana</span><br><span class="line">    restart: &quot;always&quot;</span><br><span class="line">    container_name: kibana</span><br><span class="line">    environment:</span><br><span class="line">      - ELASTICSEARCH_URL=http://elasticsearch:9200</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5601:5601&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line"> nginx:</span><br><span class="line">     image: nginx</span><br><span class="line">     restart: &quot;always&quot;</span><br><span class="line">     container_name: nginx</span><br><span class="line">     ports:</span><br><span class="line">       - &quot;80:80&quot;</span><br><span class="line">     volumes:</span><br><span class="line">        - ./nginx/html:/usr/share/nginx/html</span><br><span class="line">        - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf</span><br><span class="line">        - ./nginx/conf.d:/etc/nginx/conf.d</span><br><span class="line">        - ./nginx/logs:/var/log/nginx</span><br><span class="line">networks:</span><br><span class="line"> elk:</span><br><span class="line">  driver: bridge</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>从零开始搭建一套日志收集分析系统</title>
      <link href="/2019/03/14/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%A5%97%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"/>
      <url>/2019/03/14/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E5%A5%97%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="系统模型"><a href="#系统模型" class="headerlink" title="系统模型"></a>系统模型</h2><p><img src="/2019/03/14/从零开始搭建一套日志收集分析系统/ELK-Stack.svg" alt></p><h2 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h2><h3 id="logrus-kafka-hook-设置"><a href="#logrus-kafka-hook-设置" class="headerlink" title="logrus kafka hook 设置"></a>logrus kafka hook 设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">    &quot;os&quot;</span><br><span class="line">    &quot;log&quot;</span><br><span class="line">    &quot;time&quot;</span><br><span class="line">    &quot;strings&quot;</span><br><span class="line">    &quot;math/rand&quot;</span><br><span class="line">    &quot;crypto/tls&quot;</span><br><span class="line"></span><br><span class="line">    &quot;github.com/sirupsen/logrus&quot;</span><br><span class="line">    &quot;github.com/Shopify/sarama&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">type KafkaHook struct &#123;</span><br><span class="line">    Topic       string</span><br><span class="line">    AddHostname bool</span><br><span class="line">    Hostname    string</span><br><span class="line">    levels      []logrus.Level</span><br><span class="line">    Formatter   logrus.Formatter</span><br><span class="line">    Producer    sarama.AsyncProducer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func NewKafakaHook(levels []logrus.Level, formatter logrus.Formatter, topic string, brokers string, addHostname bool, tls *tls.Config) (*KafkaHook, error) &#123;</span><br><span class="line">    var (</span><br><span class="line">        err error</span><br><span class="line">        producer sarama.AsyncProducer</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    config := sarama.NewConfig()</span><br><span class="line">    config.Producer.RequiredAcks = sarama.WaitForLocal</span><br><span class="line">    // config.Producer.Compression = sarama.CompressionSnappy</span><br><span class="line">    config.Producer.Flush.Frequency = 500 * time.Millisecond</span><br><span class="line">    config.Producer.Timeout = 5 * time.Second</span><br><span class="line"></span><br><span class="line">    if tls != nil &#123;</span><br><span class="line">        config.Net.TLS.Enable = true</span><br><span class="line">        config.Net.TLS.Config = tls</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    producer, err = sarama.NewAsyncProducer(strings.Split(brokers, &quot;,&quot;), config)</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">        return nil, err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    go func() &#123;</span><br><span class="line">        errs := producer.Errors()</span><br><span class="line">        for &#123;</span><br><span class="line">            select &#123;</span><br><span class="line">            case err := &lt;-errs:</span><br><span class="line">                if err != nil &#123;</span><br><span class="line">                    log.Printf(&quot;Failed to send log entry to Kafka: %v\n&quot;, err)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    hostname, err := os.Hostname()</span><br><span class="line">    if err != nil &#123;</span><br><span class="line">        hostname = &quot;localhost&quot;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    hook := &amp;KafkaHook&#123;</span><br><span class="line">        topic,</span><br><span class="line">        addHostname,</span><br><span class="line">        hostname,</span><br><span class="line">        levels,</span><br><span class="line">        formatter,</span><br><span class="line">        producer,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return hook, nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (kh *KafkaHook) Fire(entry *logrus.Entry) error &#123;</span><br><span class="line">    var (</span><br><span class="line">        bt []byte</span><br><span class="line">        err error</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    if bt, err = entry.Time.MarshalBinary(); err != nil &#123;</span><br><span class="line">        return err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if kh.AddHostname &#123;</span><br><span class="line">        if _, ok := entry.Data[&quot;host&quot;]; !ok &#123;</span><br><span class="line">            entry.Data[&quot;host&quot;] = kh.Hostname</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if bt, err = kh.Formatter.Format(entry); err != nil &#123;</span><br><span class="line">        return err</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    value := sarama.ByteEncoder(bt)</span><br><span class="line"></span><br><span class="line">    kh.Producer.Input() &lt;- &amp;sarama.ProducerMessage&#123;</span><br><span class="line">        Topic: kh.Topic,</span><br><span class="line">        Value: value,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return nil</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func (kh *KafkaHook) Levels() []logrus.Level &#123;</span><br><span class="line">    return kh.levels</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">   hook, err := NewKafakaHook(</span><br><span class="line">      []logrus.Level&#123;</span><br><span class="line">         logrus.DebugLevel,</span><br><span class="line">         logrus.InfoLevel,</span><br><span class="line">         logrus.ErrorLevel,</span><br><span class="line">         logrus.WarnLevel,</span><br><span class="line">      &#125;,</span><br><span class="line">      &amp;logrus.JSONFormatter&#123;&#125;,</span><br><span class="line">      &quot;log-dev&quot;,</span><br><span class="line">      &quot;10.9.X.A:9092,10.9.X.B:9092,10.9.X.C:9092&quot;,</span><br><span class="line">      true,</span><br><span class="line">      nil,</span><br><span class="line">   )</span><br><span class="line">   if err != nil &#123;</span><br><span class="line">      log.Println(err)</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   logger := logrus.New()</span><br><span class="line">   logger.SetLevel(logrus.DebugLevel)</span><br><span class="line">   logger.Hooks.Add(hook)</span><br><span class="line"></span><br><span class="line">   n := 0</span><br><span class="line">   for &#123;</span><br><span class="line">      n++</span><br><span class="line">      r := rand.Intn(1&lt;&lt;10)</span><br><span class="line">      time.Sleep(time.Millisecond * time.Duration(r))</span><br><span class="line">      switch &#123;</span><br><span class="line">      case r &lt; 512: logger.Info(&quot;this is an info message &quot; + strconv.Itoa(n))</span><br><span class="line">      case r &gt;= 512 &amp;&amp; r &lt; 869: logger.Warn(&quot;this is a warn message &quot; + strconv.Itoa(n))</span><br><span class="line">      case r &gt;= 869 &amp;&amp; r &lt; 985: logger.Debug(&quot;this is a debug message &quot; + strconv.Itoa(n))</span><br><span class="line">      case r &gt;= 985: logger.Error(&quot;this is an error message &quot; + strconv.Itoa(n))</span><br><span class="line">      default:</span><br><span class="line">         logger.Warn(&quot;unexpected message&quot;)</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a>Filebeat</h3><h5 id="在需要抓取日志的机器上安装并配置-Filebeat"><a href="#在需要抓取日志的机器上安装并配置-Filebeat" class="headerlink" title="在需要抓取日志的机器上安装并配置 Filebeat"></a>在需要抓取日志的机器上安装并配置 Filebeat</h5><p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html</a><br>以 ubuntu:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-amd64.deb</span><br><span class="line">sudo dpkg -i filebeat-6.3.2-amd64.deb</span><br></pre></td></tr></table></figure></p><p>centos:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.2-x86_64.rpm</span><br><span class="line">sudo rpm -vi filebeat-6.3.2-x86_64.rpm</span><br></pre></td></tr></table></figure></p><blockquote><p>最好使用 6.3 版本，我试过升级到 6.4 结果原先的配置会出问题</p></blockquote><h5 id="启动和停止"><a href="#启动和停止" class="headerlink" title="启动和停止"></a>启动和停止</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start filebeat   # sudo /etc/init.d/filebeat start</span><br><span class="line">systemctl restart filebeat    # sudo /etc/init.d/filebeat restart</span><br><span class="line">systemctl stop filebeat   # sudo /etc/init.d/filebeat stop</span><br></pre></td></tr></table></figure><h5 id="默认路径"><a href="#默认路径" class="headerlink" title="默认路径:"></a>默认路径:</h5><ul><li>home: /usr/share/filebeat</li><li>bin: /usr/share/filebeat/bin</li><li>config: /etc/filebeat</li><li>data: /var/lib/filebeat</li><li>logs: /var/log/filebeat</li></ul><h5 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h5><p>编辑 filebeat.yml 文件添加输入、输出等配置，比如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">## vi /etc/filebeat/filebeat.yml</span><br><span class="line"></span><br><span class="line">## Log Input 相关属性设置: https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-input-log.html</span><br><span class="line">filebeat.inputs:</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/req/req-worker-*.log # 文件名和目录名都可以用通配符，不过 path/*/*.log 不包括 path 根目录的文件</span><br><span class="line">    fields: # 添加额外的字段</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-req&quot;</span><br><span class="line">    fields_under_root: true # field 字段会放在根索引下，否则会放在 fields 字段下</span><br><span class="line">    ignore_older: 24h # 忽略 24 小时前的文件</span><br><span class="line">    scan_frequency: 11s # 设置不同的时间，这样可以错开扫描高峰</span><br><span class="line">    max_backoff: 11s</span><br><span class="line">    backoff: 11s</span><br><span class="line">    harvester_buffer_size: 51200 # 采集的 buffer 大小</span><br><span class="line">    close_timeout: 1h # 因为我这里的文件是一个小时产生一个，所以直接设置采集器默认 1 小时关闭</span><br><span class="line">    clean_inactive: 25h # 需要大于 ignore_older + scan_frequency，有效地清理可以减小 registry 文件的大小和当中记录的文件条目数量</span><br><span class="line">    harvester_limit: 10 # 限制最多爬取个数，默认不限制，如果碰到文件数很多一开始会占用大量 cpu</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/push/push-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-push&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 19s</span><br><span class="line">    max_backoff: 19s</span><br><span class="line">    backoff: 19s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/send/send-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-send&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 13s</span><br><span class="line">    max_backoff: 13s</span><br><span class="line">    backoff: 13s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/sync/sync-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-sync&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 17s</span><br><span class="line">    max_backoff: 17s</span><br><span class="line">    backoff: 17s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">      - /var/log/delete/delete-worker-*.log</span><br><span class="line">    fields:</span><br><span class="line">      log_topic: &quot;log-test&quot;</span><br><span class="line">      service: &quot;backend-delete&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 71s</span><br><span class="line">    max_backoff: 71s</span><br><span class="line">    backoff: 71s</span><br><span class="line">    harvester_buffer_size: 51200</span><br><span class="line">    close_timeout: 1h</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    harvester_limit: 10</span><br><span class="line">  - type: log</span><br><span class="line">    enabled: true</span><br><span class="line">    paths:</span><br><span class="line">        - /var/log/php/error.log</span><br><span class="line">    fields:</span><br><span class="line">        log_topic: &quot;log-im&quot;</span><br><span class="line">        service: &quot;backend-php-error&quot;</span><br><span class="line">    fields_under_root: true</span><br><span class="line">    ignore_older: 24h</span><br><span class="line">    scan_frequency: 23s</span><br><span class="line">    max_backoff: 23s</span><br><span class="line">    backoff: 23s</span><br><span class="line">    clean_inactive: 25h</span><br><span class="line">    close_renamed: true # 因为这个日志文件会定期重命名并压缩，所以设置 close_renamed 可以关闭采集器</span><br><span class="line">    multiline.pattern: &apos;^\[[0-9]&#123;2&#125;-[A-Z]&#123;1&#125;[a-z]&#123;2&#125;-[0-9]&#123;4&#125;&apos; # 合并多行日志，将类似 [06-Sep-2018 ... 开头的日志向后合并</span><br><span class="line">    multiline.negate: true</span><br><span class="line">    multiline.match: after</span><br><span class="line">    harvester_limit: 10</span><br><span class="line"></span><br><span class="line">## Kafka Output 相关属性设置: https://www.elastic.co/guide/en/beats/filebeat/current/kafka-output.html</span><br><span class="line">output.kafka:</span><br><span class="line">  enabled: true</span><br><span class="line">  hosts: [&quot;10.10.X.A:9092&quot;, &quot;10.10.X.B:9092&quot;, &quot;10.10.X.C:9092&quot;]</span><br><span class="line">  topic: &apos;%&#123;[log_topic]&#125;&apos;</span><br><span class="line">  codec.format:</span><br><span class="line">    string: &apos;%&#123;[beat][hostname]&#125; %&#123;[service]&#125; %&#123;[message]&#125;&apos; # 传给 logstash 时可以用 grok 过滤插件设置 `match =&gt; &#123; &quot;message&quot; =&gt; &quot;^%&#123;DATA:hostname&#125; %&#123;DATA:service&#125; (?&lt;message&gt;.*)&quot;&#125;` 解析</span><br><span class="line">    # 如果设成 ‘%&#123;[message]&#125;’，则是原样转发消息</span><br><span class="line">  partition.round_robin:</span><br><span class="line">    reachable_only: false</span><br><span class="line">  required_acks: 1</span><br><span class="line">  compression: none # 默认是 gzip，如果像节省开销可以设成 none</span><br><span class="line">  bulk_max_size: 100</span><br><span class="line">  max_message_bytes: 1000000 # 不要超过 kafka server 端设置的 message.max.size，否则超过的部分会被丢弃</span><br><span class="line"></span><br><span class="line">output.file:</span><br><span class="line">  enabled: false</span><br><span class="line">  path: /home/ubuntu/test-log</span><br><span class="line">  filename: output.log</span><br><span class="line">  permissions: 0644</span><br><span class="line">  codec.format:</span><br><span class="line">    string: &apos;%&#123;[message]&#125;&apos;</span><br></pre></td></tr></table></figure></p><p><a href="https://cloud.tencent.com/developer/article/1006051" title="Filebeat 配置详解" target="_blank" rel="noopener">Filebeat 配置详解</a><br>假设 Filebeat 要抓取的是非结构化日志格式:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">Mon Sep 10 2018 12:06:16 GMT+0800 (CST) - info: type: SyncSessionRangeService  uid:9182093812301298392103&#123;&#125;</span><br><span class="line"></span><br><span class="line">18-09-07 08:19:43 - info: GRPC REQUEST &amp; RESPONSE&#123;</span><br><span class="line">        &quot;uid&quot;: 1290381298494,</span><br><span class="line">        &quot;type&quot;: &quot;SyncSessionRangeService&quot;,</span><br><span class="line">        &quot;data&quot;: &#123;</span><br><span class="line">            &quot;session_id&quot;: 123456,</span><br><span class="line">            &quot;session_type&quot;: 2,</span><br><span class="line">            &quot;start_id&quot;: 0,</span><br><span class="line">            &quot;stop_id&quot;: 3</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;localId&quot;: 349058034598,</span><br><span class="line">        &quot;result&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: 5,</span><br><span class="line">            &quot;is_sync&quot;: true,</span><br><span class="line">            &quot;is_ack&quot;: true,</span><br><span class="line">            &quot;require_ack&quot;: false,</span><br><span class="line">            &quot;error&quot;: 0,</span><br><span class="line">            &quot;continue&quot;: false,</span><br><span class="line">            &quot;sync_local_id&quot;: 0,</span><br><span class="line">            &quot;messages&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">18-09-06 22:07:33 - info: type: SyncSessionRangeService  uid:20373933&#123;&#125;</span><br><span class="line"></span><br><span class="line">18-09-07 08:19:43 - info: GRPC REQUEST &amp; RESPONSE&#123;</span><br><span class="line">            &quot;uid&quot;: 5792715,</span><br><span class="line">            &quot;type&quot;: &quot;SyncSessionRangeService&quot;,</span><br><span class="line">            &quot;data&quot;: &#123;</span><br><span class="line">                &quot;session_id&quot;: 13416794,</span><br><span class="line">                &quot;session_type&quot;: 2,</span><br><span class="line">                &quot;start_id&quot;: 0,</span><br><span class="line">                &quot;stop_id&quot;: 3</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;localId&quot;: 1536279501,</span><br><span class="line">            &quot;result&quot;: &#123;</span><br><span class="line">                &quot;type&quot;: 5,</span><br><span class="line">                &quot;is_sync&quot;: true,</span><br><span class="line">                &quot;is_ack&quot;: true,</span><br><span class="line">                &quot;require_ack&quot;: false,</span><br><span class="line">                &quot;error&quot;: 0,</span><br><span class="line">                &quot;continue&quot;: false,</span><br><span class="line">                &quot;sync_local_id&quot;: 0,</span><br><span class="line">                &quot;messages&quot;: []</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">[08/Sep/2018:01:49:55 +0800] check photo https://sgchatfiles.bldimg.com/2018/9/8/1/49/16263641_1536342594629.jpg</span><br><span class="line"></span><br><span class="line">[08/Sep/2018:01:49:55 +0800] check &quot;result&quot;: &#123;</span><br><span class="line">    &quot;type&quot;: 5,</span><br><span class="line">    &quot;is_sync&quot;: true,</span><br><span class="line">    &quot;is_ack&quot;: true,</span><br><span class="line">    &quot;require_ack&quot;: false,</span><br><span class="line">    &quot;error&quot;: 0,</span><br><span class="line">    &quot;continue&quot;: false,</span><br><span class="line">    &quot;sync_local_id&quot;: 0,</span><br><span class="line">    &quot;messages&quot;: []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>对于多行日志，使用 multiline.pattern 处理:<a href="https://www.elastic.co/guide/en/beats/filebeat/current/multiline-examples.html" target="_blank" rel="noopener">参考</a></p><h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p><a href="https://262986832.github.io/2019/03/14/%E5%AE%89%E8%A3%85kafka/" target="_blank" rel="noopener">安装过程</a></p><h3 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h3><p>ELK 主要是以 docker-elk 为模板进行搭建，选择的版本是 6.3<br>不过该项目是搭建在单节点上的配置，如果是用在生产环境的多主机上要修改很多地方，这是我修改的 docker-elk<br>创建文件目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/elk/elasticsearch/config</span><br><span class="line">mkdir -p /opt/elk/elasticsearch/data</span><br><span class="line">mkdir -p /opt/elk/extensions/curator/curator</span><br><span class="line">mkdir -p /opt/elk/extensions/logspout</span><br><span class="line">mkdir -p /opt/elk/kibana/config</span><br><span class="line">mkdir -p /opt/elk/logstash/config</span><br><span class="line">mkdir -p /opt/elk/logstash/pipeline</span><br><span class="line">$ tree .</span><br><span class="line">.</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">├── elasticsearch</span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── elasticsearch.yml</span><br><span class="line">│   └──data</span><br><span class="line">├── extensions</span><br><span class="line">│   ├── curator</span><br><span class="line">│   │   ├── config</span><br><span class="line">│   │   │   ├── curator.yml</span><br><span class="line">│   │   │   └── delete_log_files_curator.yml</span><br><span class="line">│   │   ├── curator-compose.yml</span><br><span class="line">│   │   ├── </span><br><span class="line">│   │   ├── entrypoint.sh</span><br><span class="line">│   │   └── README.md</span><br><span class="line">│   ├── logspout</span><br><span class="line">│   │   ├── build.sh</span><br><span class="line">│   │   ├── Dockerfile</span><br><span class="line">│   │   ├── logspout-compose.yml</span><br><span class="line">│   │   ├── modules.go</span><br><span class="line">│   │   └── README.md</span><br><span class="line">│   └── README.md</span><br><span class="line">├── kibana</span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── kibana.yml</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">├── LICENSE</span><br><span class="line">├── logstash</span><br><span class="line">│   ├── config</span><br><span class="line">│   │   └── logstash.yml</span><br><span class="line">│   ├── Dockerfile</span><br><span class="line">│   └── pipeline</span><br><span class="line">│       └── logstash.conf</span><br><span class="line">└── README.md</span><br></pre></td></tr></table></figure></p><p><em>docker-compose.yml</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">#vi docker-compose.yml </span><br><span class="line">version: &apos;2.2&apos; # version 2.2 以上加 docker-compose 1.16+ 才支持 cpus 的设置项</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  elasticsearch:</span><br><span class="line">    image: elasticsearch</span><br><span class="line">    container_name: elasticsearch</span><br><span class="line">    volumes:</span><br><span class="line">      - ./elasticsearch/data:/usr/share/elasticsearch/data # 设置 es 数据存放目录</span><br><span class="line">      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9200:9200&quot;</span><br><span class="line">      - &quot;9300:9300&quot;</span><br><span class="line">    cpus: 1.5 # 限制 cpu 的使用，两核的处理器设置 1.5 代表最多占用 1.5/2 (75%) 的 cpu</span><br><span class="line">    mem_limit: 6g # 限制容器最多占用 6g 内存</span><br><span class="line">    ulimits: # 必须设置此项 bootstrap.memory_lock 才能生效</span><br><span class="line">      memlock:</span><br><span class="line">        soft: -1</span><br><span class="line">        hard: -1</span><br><span class="line">    environment:</span><br><span class="line">      ES_JAVA_OPTS: &quot;-Xmx3g -Xms3g&quot; # 设置 Java 堆内存大小，最好设置成主机的一半但也不能超过 32g</span><br><span class="line">      PUBLISH_HOST: &quot;10.5.74.18&quot; # host ip</span><br><span class="line">      NODE_NAME: &quot;es-node-1&quot; # 新的节点，需要修改</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">      </span><br><span class="line">  kibana:</span><br><span class="line">    image: kibana</span><br><span class="line">    container_name: kibana</span><br><span class="line">    volumes:</span><br><span class="line">      - ./kibana/config/:/usr/share/kibana/config:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5601:5601&quot;</span><br><span class="line">    environment:</span><br><span class="line">      - ELASTICSEARCH_URL=http://10.5.74.18:9200</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line">      </span><br><span class="line">  logstash:</span><br><span class="line">    image: logstash</span><br><span class="line">    container_name: logstash</span><br><span class="line">    volumes:</span><br><span class="line">      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro</span><br><span class="line">      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5000:5000&quot;</span><br><span class="line">    cpus: 1.5</span><br><span class="line">    mem_limit: 1g</span><br><span class="line">    environment:</span><br><span class="line">      LS_JAVA_OPTS: &quot;-Xmx512m -Xms512m&quot;</span><br><span class="line">    restart: always</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line"></span><br><span class="line">  cerebro:</span><br><span class="line">    image: yannart/cerebro</span><br><span class="line">    container_name: cerebro</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9000:9000&quot;</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line">networks:</span><br><span class="line"> elk:</span><br><span class="line">  driver: bridge</span><br></pre></td></tr></table></figure></p><h3 id="logstash-配置"><a href="#logstash-配置" class="headerlink" title="logstash 配置"></a>logstash 配置</h3><p>这里只是作为同一个 group 里的消费者，按一定方式分摊消费 kafka 队列中的消息<br><em>logstash.conf</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">#vi logstash/pipeline/logstash.conf </span><br><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;10.5.74.18:9092,10.5.74.18:9092,10.5.74.18:9092&quot;</span><br><span class="line">        consumer_threads =&gt; 3 # 一般设为 Partition 的数目即可</span><br><span class="line">        decorate_events =&gt; false</span><br><span class="line">        topics =&gt; [&quot;log-im&quot;]</span><br><span class="line">        group_id =&gt; &quot;group-log-im&quot;</span><br><span class="line">        type =&gt; &quot;log-im&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;10.5.74.18:9092,10.5.74.18:9092,10.5.74.18:9092&quot;</span><br><span class="line">        consumer_threads =&gt; 3</span><br><span class="line">        decorate_events =&gt; false</span><br><span class="line">        topics =&gt; [&quot;log-dev&quot;]</span><br><span class="line">        group_id =&gt; &quot;group-log-dev&quot;</span><br><span class="line">        type =&gt; &quot;log-dev&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">## Add your filters / logstash plugins configuration here</span><br><span class="line">filter &#123;</span><br><span class="line">    mutate &#123;</span><br><span class="line">        remove_field =&gt; [ &quot;@version&quot; ]</span><br><span class="line">    &#125;</span><br><span class="line">    if [type] == &quot;log-im&quot; &#123;</span><br><span class="line">        # grok 插件可以将非结构化日志解析成结构化的</span><br><span class="line">        # 测试工具: http://grokdebug.herokuapp.com</span><br><span class="line">        # 推荐阅读: https://www.elastic.co/blog/do-you-grok-grok</span><br><span class="line">        grok &#123;</span><br><span class="line">            match =&gt; &#123; &quot;message&quot; =&gt; &quot;^%&#123;DATA:hostname&#125; %&#123;DATA:service&#125; (?&lt;message&gt;.*)&quot; &#125;</span><br><span class="line">            overwrite =&gt; [ &quot;message&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        grok &#123;</span><br><span class="line">            match =&gt; &#123;</span><br><span class="line">                &quot;message&quot; =&gt; [</span><br><span class="line">                    &quot;^\[%&#123;DATA:time&#125;\] (?&lt;message&gt;.*)&quot;,</span><br><span class="line">                    &quot;^(?&lt;time&gt;[T|M|W|S|F]&#123;1&#125;[a-z]&#123;2&#125; [J|F|M|A|S|O|N|D]&#123;1&#125;[a-z]&#123;2&#125; [0-9]&#123;2&#125; [0-9]&#123;4&#125; [0-9]&#123;2&#125;:[0-9]&#123;2&#125;:[0-9]&#123;2&#125; [GMT+]&#123;4&#125;[0-9]&#123;4&#125; [(CST)]&#123;5&#125;) - %&#123;LOGLEVEL:level&#125;: (?&lt;message&gt;.*)&quot;,</span><br><span class="line">                    &quot;^(?&lt;time&gt;[0-9]&#123;2&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125; [0-9]&#123;2&#125;:[0-9]&#123;2&#125;:[0-9]&#123;2&#125;) - %&#123;LOGLEVEL:level&#125;: (?&lt;message&gt;.*)&quot;,</span><br><span class="line">                    &quot;^(?&lt;message&gt;.*)&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">            overwrite =&gt; [ &quot;message&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        json &#123;</span><br><span class="line">            source =&gt; &quot;message&quot;</span><br><span class="line">            skip_on_invalid_json =&gt; true</span><br><span class="line">            remove_field =&gt; [ &quot;message&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        date &#123;</span><br><span class="line">            match =&gt; [ &quot;time&quot;, &quot;ISO8601&quot;, &quot;EEE MMM dd yyyy HH:mm:ss &apos;GMT&apos;Z &apos;(CST)&apos;&quot;, &quot;dd/MMM/yyyy:HH:mm:ss Z&quot;, &quot;yy-MM-dd HH:mm:ss&quot;, &quot;dd-MMM-yyyy HH:mm:ss ZZZ&quot;, &quot;yyyy-MM-dd HH:mm:ss ZZ&quot;, &quot;yyyy-MM-dd HH:mm ZZ&quot; ]</span><br><span class="line">            remove_field =&gt; [ &quot;time&quot; ]</span><br><span class="line">        &#125;</span><br><span class="line">        if [service] == &quot;backend-php-error&quot; &#123;</span><br><span class="line">            mutate &#123;</span><br><span class="line">                add_field =&gt; &#123; &quot;level&quot; =&gt; &quot;error&quot; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    ## 根据 type 区分不同的 topic 日志，然后存入不同的 index 中，方便 Kibana 聚合</span><br><span class="line">    if [type] == &quot;log-im&quot; &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;10.5.74.18:9200&quot;, &quot;10.42.75.252:9200&quot;, &quot;10.42.111.182:9200&quot;]</span><br><span class="line">            index =&gt; &quot;%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;&quot; # 最好使用日期，一天一个索引，这样方便删除旧索引</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if [type] == &quot;log-dev-2&quot; &#123;</span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; [&quot;10.5.74.18:9200&quot;, &quot;10.42.75.252:9200&quot;, &quot;10.42.111.182:9200&quot;]</span><br><span class="line">            index =&gt; &quot;log-dev-2&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><em>logstash.yml:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vi logstash/config/logstash.yml</span><br><span class="line">## Default Logstash configuration from logstash-docker.</span><br><span class="line">## from https://github.com/elastic/logstash-docker/blob/master/build/logstash/config/logstash-oss.yml</span><br><span class="line">http.host: &quot;0.0.0.0&quot;</span><br><span class="line">path.config: /usr/share/logstash/pipeline</span><br><span class="line"></span><br><span class="line">pipeline.workers: 4 # 设置成 cpu 核数或者其倍数</span><br><span class="line">pipeline.output.workers: 4</span><br><span class="line">pipeline.batch.size: 1000</span><br><span class="line">pipeline.batch.delay: 10</span><br></pre></td></tr></table></figure></p><h3 id="ES-的集群设置"><a href="#ES-的集群设置" class="headerlink" title="ES 的集群设置"></a>ES 的集群设置</h3><p>ES 节点有很多种角色，比如常见的 master、data、injest 节点，我这里是将三个节点作为 master 和 injest，另外三个作为 data 节点。<br><em>elasticsearch.yml:</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">## vi elasticsearch/config/elasticsearch.yml</span><br><span class="line"></span><br><span class="line">## Default Elasticsearch configuration from elasticsearch-docker.</span><br><span class="line">## from https://github.com/elastic/elasticsearch-docker/blob/master/build/elasticsearch/elasticsearch.yml</span><br><span class="line">cluster.name: &quot;elk-cluster&quot;</span><br><span class="line"></span><br><span class="line">node.name: $&#123;NODE_NAME&#125;</span><br><span class="line">node.master: true</span><br><span class="line"></span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">network.publish_host: $&#123;PUBLISH_HOST&#125;</span><br><span class="line"></span><br><span class="line">## https://www.elastic.co/guide/en/elasticsearch/reference/6.3/setup-configuration-memory.html</span><br><span class="line">## 最好按照官方说的关闭内存交换并设置此项为 true，容器的话需要设置 ulimit</span><br><span class="line">bootstrap.memory_lock: true</span><br><span class="line"></span><br><span class="line">## 集群单播 ip</span><br><span class="line">discovery.zen.ping.unicast.hosts: [&quot;10.5.74.18:9300&quot;, &quot;10.5.74.19:9300&quot;, &quot;10.5.74.20:9300&quot;]</span><br><span class="line">discovery.zen.fd.ping_timeout: 120s</span><br><span class="line">discovery.zen.fd.ping_retries: 6</span><br><span class="line">discovery.zen.fd.ping_interval: 30s</span><br><span class="line"></span><br><span class="line">## 设置此项，当 fielddata 达到预设值时会清除旧数据，有利于新数据的写入</span><br><span class="line">indices.fielddata.cache.size: 30%</span><br><span class="line"></span><br><span class="line">## 避免集群整个重启时频繁交换分片的问题</span><br><span class="line">gateway.recover_after_nodes: 2</span><br><span class="line">gateway.expected_nodes: 3</span><br><span class="line">gateway.recover_after_time: 5m</span><br><span class="line"></span><br><span class="line"># 防止脑裂，推荐设成: 候选主节点数除二加一</span><br><span class="line"># recommend set: (masters) / 2 + 1</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure></p><h3 id="配置Kibana"><a href="#配置Kibana" class="headerlink" title="配置Kibana"></a>配置Kibana</h3><p>默认访问同一主机上的 ES 节点即可<br><em>kibana.yml</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">## vi kibana/config/kibana.yml</span><br><span class="line"></span><br><span class="line">## Default Kibana configuration from kibana-docker.</span><br><span class="line">## from https://github.com/elastic/kibana-docker/blob/master/build/kibana/config/kibana.yml</span><br><span class="line">server.name: kibana</span><br><span class="line">server.host: &quot;0&quot;</span><br><span class="line">elasticsearch.requestTimeout: 90000</span><br></pre></td></tr></table></figure></p><blockquote><p>修改主机配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w vm.max_map_count=262144</span><br><span class="line">echo &quot;vm.max_map_count=262144&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> elk </tag>
            
            <tag> Filebeat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker compose安装</title>
      <link href="/2019/03/14/docker-compose%E5%AE%89%E8%A3%85/"/>
      <url>/2019/03/14/docker-compose%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h5 id="安装-Docker-Compose"><a href="#安装-Docker-Compose" class="headerlink" title="安装 Docker-Compose"></a>安装 Docker-Compose</h5><h5 id="下载最新版本的-docker-compose-到-usr-bin-目录下"><a href="#下载最新版本的-docker-compose-到-usr-bin-目录下" class="headerlink" title="下载最新版本的 docker-compose 到 /usr/bin 目录下"></a>下载最新版本的 docker-compose 到 /usr/bin 目录下</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -L https://github.com/docker/compose/releases/download/1.23.2/docker-compose-`uname -s`-`uname -m` -o /usr/bin/docker-compose</span><br></pre></td></tr></table></figure><h5 id="给-docker-compose-授权"><a href="#给-docker-compose-授权" class="headerlink" title="给 docker-compose 授权"></a>给 docker-compose 授权</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x /usr/bin/docker-compose</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>kafka安装</title>
      <link href="/2019/03/14/%E5%AE%89%E8%A3%85kafka/"/>
      <url>/2019/03/14/%E5%AE%89%E8%A3%85kafka/</url>
      
        <content type="html"><![CDATA[<hr><p>通过docker可以很方便的搭建kafka集群作为本地测试环境使用<br>使用docker-compose进行搭建，包含zookpper服务、kafka broker、kafka-manager。</p><h4 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/kafka</span><br><span class="line">mkdir -p /opt/kafka/kafka-logs</span><br><span class="line">mkdir -p /opt/kafka/zooData</span><br><span class="line">cd /opt/kafka</span><br><span class="line">vi docker-compose.yml</span><br></pre></td></tr></table></figure><h4 id="docker-compose-yml文件内容："><a href="#docker-compose-yml文件内容：" class="headerlink" title="docker-compose.yml文件内容："></a>docker-compose.yml文件内容：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line">  zookeeper:</span><br><span class="line">    image: wurstmeister/zookeeper</span><br><span class="line">    volumes:</span><br><span class="line">      - ./zooData:/data</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;2181:2181&quot;</span><br><span class="line">       </span><br><span class="line">  kafka:</span><br><span class="line">    image: wurstmeister/kafka</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9092:9092&quot;</span><br><span class="line">    environment:</span><br><span class="line">      KAFKA_ADVERTISED_HOST_NAME: 10.5.74.18</span><br><span class="line">      KAFKA_MESSAGE_MAX_BYTES: 2000000</span><br><span class="line">      KAFKA_CREATE_TOPICS: &quot;Topic1:1:3,Topic2:1:1:compact&quot;</span><br><span class="line">      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181</span><br><span class="line">    volumes:</span><br><span class="line">      - ./kafka-logs:/kafka</span><br><span class="line">      - /var/run/docker.sock:/var/run/docker.sock</span><br><span class="line"> </span><br><span class="line">  kafka-manager:</span><br><span class="line">    image: sheepkiller/kafka-manager</span><br><span class="line">    ports:</span><br><span class="line">      - 9020:9000</span><br><span class="line">    environment:</span><br><span class="line">      ZK_HOSTS: zookeeper:2181</span><br></pre></td></tr></table></figure><h4 id="启动kakfa集群"><a href="#启动kakfa集群" class="headerlink" title="启动kakfa集群"></a>启动kakfa集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">docker-compose up -d</span><br><span class="line"></span><br><span class="line"># 增加更多Broker：</span><br><span class="line">docker-compose scale kafka=3</span><br><span class="line"> </span><br><span class="line"># 合并：</span><br><span class="line">docker-compose up --scale kafka=3</span><br></pre></td></tr></table></figure><h4 id="读写验证"><a href="#读写验证" class="headerlink" title="读写验证"></a>读写验证</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it kafka_kafka_1 /bin/bash</span><br><span class="line">/opt/kafka/bin/kafka-topics.sh --create --zookeeper 172.18.0.4:2181 --replication-factor 1 --partitions 1 --topic my-test</span><br></pre></td></tr></table></figure><h4 id="列出主题："><a href="#列出主题：" class="headerlink" title="列出主题："></a>列出主题：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">/opt/kafka/bin/kafka-topics.sh --list --zookeeper 172.18.0.4:2181</span><br></pre></td></tr></table></figure><h4 id="发送消息："><a href="#发送消息：" class="headerlink" title="发送消息："></a>发送消息：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-console-producer.sh --broker-list 172.18.0.3:9092 --topic my-test</span><br></pre></td></tr></table></figure><h4 id="发送消息：-1"><a href="#发送消息：-1" class="headerlink" title="发送消息："></a>发送消息：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server 172.18.0.3:9092 --topic my-test --from-beginning</span><br></pre></td></tr></table></figure><h4 id="列出消费者组："><a href="#列出消费者组：" class="headerlink" title="列出消费者组："></a>列出消费者组：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --list</span><br></pre></td></tr></table></figure><h4 id="查看消费者组："><a href="#查看消费者组：" class="headerlink" title="查看消费者组："></a>查看消费者组：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server 127.0.0.1:9092 --describe --group test_group</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>hexo 添加本地图片</title>
      <link href="/2019/03/14/hexo-%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/"/>
      <url>/2019/03/14/hexo-%E6%B7%BB%E5%8A%A0%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/</url>
      
        <content type="html"><![CDATA[<p><img src="/2019/03/14/hexo-添加本地图片/20190314140451.png" alt></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>docker 安装</title>
      <link href="/2019/03/14/hello-everyone/"/>
      <url>/2019/03/14/hello-everyone/</url>
      
        <content type="html"><![CDATA[<h5 id="准备工作"><a href="#准备工作" class="headerlink" title="* 准备工作"></a>* 准备工作</h5><p>Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure><h5 id="问题，卸载旧版本的包-区别？"><a href="#问题，卸载旧版本的包-区别？" class="headerlink" title="* 问题，卸载旧版本的包 区别？"></a>* 问题，卸载旧版本的包 区别？</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum erase docker-common-2:1.12.6-68.gitec8512b.el7.centos.x86_64</span><br></pre></td></tr></table></figure><h5 id="卸载旧版本"><a href="#卸载旧版本" class="headerlink" title="*  卸载旧版本"></a>*  卸载旧版本</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">                      docker-client \</span><br><span class="line">                      docker-client-latest \</span><br><span class="line">                      docker-common \</span><br><span class="line">                      docker-latest \</span><br><span class="line">                      docker-latest-logrotate \</span><br><span class="line">                      docker-logrotate \</span><br><span class="line">                      docker-selinux \</span><br><span class="line">                      docker-engine-selinux \</span><br><span class="line">                      docker-engine</span><br></pre></td></tr></table></figure><h5 id="使用-yum-安装"><a href="#使用-yum-安装" class="headerlink" title="* 使用 yum 安装"></a>* 使用 yum 安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils \</span><br><span class="line">               device-mapper-persistent-data \</span><br><span class="line">               lvm2</span><br></pre></td></tr></table></figure><h5 id="鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。执行下面的命令添加-yum-软件源："><a href="#鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。执行下面的命令添加-yum-软件源：" class="headerlink" title="* 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。执行下面的命令添加 yum 软件源："></a>* 鉴于国内网络问题，强烈建议使用国内源，官方源请在注释中查看。执行下面的命令添加 yum 软件源：</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager \</span><br><span class="line">        --add-repo \</span><br><span class="line">        https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><h5 id="官方源"><a href="#官方源" class="headerlink" title="*  官方源"></a>*  官方源</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \  https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><h5 id="由于k8s的支持问题，我们选择，安装17-03-2-ce版本"><a href="#由于k8s的支持问题，我们选择，安装17-03-2-ce版本" class="headerlink" title="* 由于k8s的支持问题，我们选择，安装17.03.2.ce版本"></a>* 由于k8s的支持问题，我们选择，安装17.03.2.ce版本</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line"></span><br><span class="line">yum makecache fast</span><br><span class="line"></span><br><span class="line">yum install -y --setopt=obsoletes=0 docker-ce-17.03.2.ce-1.el7.centos docker-ce-selinux-17.03.2.ce-1.el7.centos</span><br></pre></td></tr></table></figure><h5 id="启动-Docker-CE"><a href="#启动-Docker-CE" class="headerlink" title="* 启动 Docker CE"></a>* 启动 Docker CE</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure><h5 id="测试-Docker-是否安装正确"><a href="#测试-Docker-是否安装正确" class="headerlink" title="* 测试 Docker 是否安装正确"></a>* 测试 Docker 是否安装正确</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure><h5 id="Ubuntu-16-04-、Debian-8-、CentOS-7-加速"><a href="#Ubuntu-16-04-、Debian-8-、CentOS-7-加速" class="headerlink" title="Ubuntu 16.04+、Debian 8+、CentOS 7 加速"></a>Ubuntu 16.04+、Debian 8+、CentOS 7 加速</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi  /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">      &quot;registry-mirrors&quot;: [</span><br><span class="line">        &quot;https://registry.docker-cn.com&quot;</span><br><span class="line">      ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。之后重新启动服务。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload &amp;&amp; systemctl restart docker</span><br></pre></td></tr></table></figure></p><h5 id="CentOS7查看和关闭防火墙"><a href="#CentOS7查看和关闭防火墙" class="headerlink" title="CentOS7查看和关闭防火墙"></a>CentOS7查看和关闭防火墙</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --state</span><br><span class="line"></span><br><span class="line">systemctl stop firewalld.service</span><br><span class="line"></span><br><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/03/14/hello-world/"/>
      <url>/2019/03/14/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
